{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonjoohyung/anaconda/envs/keras/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/sonjoohyung/anaconda/envs/keras/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "(X_train, Y_train),(X_test, Y_test)=mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784).astype('float32')/255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32')/255.0\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.6877 - acc: 0.8215\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.3555 - acc: 0.8998\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.3101 - acc: 0.9115\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.2829 - acc: 0.9196\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2621 - acc: 0.9257\n",
      "10000/10000 [==============================] - 0s 17us/step\n",
      "loss and matrics : [0.24270050057172776, 0.9285]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=5, batch_size=32)\n",
    "\n",
    "loss_and_matrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('loss and matrics : ' + str(loss_and_matrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('mnist_mlp_model.h5')\n",
    "model = load_model('mnist_mlp_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.2356 - acc: 0.9344 - val_loss: 0.2045 - val_acc: 0.9405\n",
      "Epoch 2/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.1932 - acc: 0.9458 - val_loss: 0.1738 - val_acc: 0.9505\n",
      "Epoch 3/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1640 - acc: 0.9542 - val_loss: 0.1512 - val_acc: 0.9559\n",
      "Epoch 4/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1434 - acc: 0.9593 - val_loss: 0.1399 - val_acc: 0.9604\n",
      "Epoch 5/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.1283 - acc: 0.9644 - val_loss: 0.1319 - val_acc: 0.9613\n",
      "Epoch 6/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1159 - acc: 0.9673 - val_loss: 0.1172 - val_acc: 0.9666\n",
      "Epoch 7/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.1063 - acc: 0.9702 - val_loss: 0.1126 - val_acc: 0.9683\n",
      "Epoch 8/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0983 - acc: 0.9720 - val_loss: 0.1086 - val_acc: 0.9679\n",
      "Epoch 9/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0918 - acc: 0.9739 - val_loss: 0.1047 - val_acc: 0.9708\n",
      "Epoch 10/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0857 - acc: 0.9758 - val_loss: 0.1016 - val_acc: 0.9707\n",
      "Epoch 11/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0806 - acc: 0.9769 - val_loss: 0.0964 - val_acc: 0.9719\n",
      "Epoch 12/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0758 - acc: 0.9784 - val_loss: 0.0949 - val_acc: 0.9731\n",
      "Epoch 13/1000\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0718 - acc: 0.9793 - val_loss: 0.0918 - val_acc: 0.9721\n",
      "Epoch 14/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0678 - acc: 0.9809 - val_loss: 0.0904 - val_acc: 0.9743\n",
      "Epoch 15/1000\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0642 - acc: 0.9815 - val_loss: 0.0910 - val_acc: 0.9744\n",
      "Epoch 16/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0611 - acc: 0.9830 - val_loss: 0.0888 - val_acc: 0.9733\n",
      "Epoch 17/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0584 - acc: 0.9834 - val_loss: 0.0885 - val_acc: 0.9726\n",
      "Epoch 18/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0553 - acc: 0.9846 - val_loss: 0.0886 - val_acc: 0.9731\n",
      "Epoch 19/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0530 - acc: 0.9853 - val_loss: 0.0850 - val_acc: 0.9749\n",
      "Epoch 20/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0507 - acc: 0.9864 - val_loss: 0.0855 - val_acc: 0.9744\n",
      "Epoch 21/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0480 - acc: 0.9872 - val_loss: 0.0828 - val_acc: 0.9754\n",
      "Epoch 22/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0462 - acc: 0.9876 - val_loss: 0.0843 - val_acc: 0.9740\n",
      "Epoch 23/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0444 - acc: 0.9880 - val_loss: 0.0845 - val_acc: 0.9739\n",
      "Epoch 24/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0427 - acc: 0.9884 - val_loss: 0.0847 - val_acc: 0.9752\n",
      "Epoch 25/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0408 - acc: 0.9893 - val_loss: 0.0807 - val_acc: 0.9757\n",
      "Epoch 26/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0394 - acc: 0.9896 - val_loss: 0.0825 - val_acc: 0.9749\n",
      "Epoch 27/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0376 - acc: 0.9904 - val_loss: 0.0813 - val_acc: 0.9749\n",
      "Epoch 28/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0364 - acc: 0.9907 - val_loss: 0.0810 - val_acc: 0.9755\n",
      "Epoch 29/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0348 - acc: 0.9913 - val_loss: 0.0817 - val_acc: 0.9767\n",
      "Epoch 30/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0334 - acc: 0.9915 - val_loss: 0.0841 - val_acc: 0.9758\n",
      "Epoch 31/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0322 - acc: 0.9925 - val_loss: 0.0818 - val_acc: 0.9766\n",
      "Epoch 32/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0310 - acc: 0.9922 - val_loss: 0.0821 - val_acc: 0.9757\n",
      "Epoch 33/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0299 - acc: 0.9929 - val_loss: 0.0825 - val_acc: 0.9747\n",
      "Epoch 34/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0288 - acc: 0.9931 - val_loss: 0.0816 - val_acc: 0.9761\n",
      "Epoch 35/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0277 - acc: 0.9933 - val_loss: 0.0807 - val_acc: 0.9766\n",
      "Epoch 36/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0268 - acc: 0.9938 - val_loss: 0.0823 - val_acc: 0.9760\n",
      "Epoch 37/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0258 - acc: 0.9944 - val_loss: 0.0836 - val_acc: 0.9762\n",
      "Epoch 38/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0249 - acc: 0.9942 - val_loss: 0.0821 - val_acc: 0.9768\n",
      "Epoch 39/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0240 - acc: 0.9947 - val_loss: 0.0840 - val_acc: 0.9763\n",
      "Epoch 40/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0231 - acc: 0.9953 - val_loss: 0.0859 - val_acc: 0.9753\n",
      "Epoch 41/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0223 - acc: 0.9953 - val_loss: 0.0830 - val_acc: 0.9764\n",
      "Epoch 42/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0214 - acc: 0.9955 - val_loss: 0.0825 - val_acc: 0.9767\n",
      "Epoch 43/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0208 - acc: 0.9957 - val_loss: 0.0844 - val_acc: 0.9758\n",
      "Epoch 44/1000\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0200 - acc: 0.9961 - val_loss: 0.0833 - val_acc: 0.9766\n",
      "Epoch 45/1000\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.0196 - acc: 0.9960 - val_loss: 0.0837 - val_acc: 0.9765\n",
      "Epoch 46/1000\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0186 - acc: 0.9966 - val_loss: 0.0839 - val_acc: 0.9760\n",
      "Epoch 47/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0181 - acc: 0.9967 - val_loss: 0.0851 - val_acc: 0.9763\n",
      "Epoch 48/1000\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0175 - acc: 0.9970 - val_loss: 0.0854 - val_acc: 0.9764\n",
      "Epoch 49/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0170 - acc: 0.9968 - val_loss: 0.0887 - val_acc: 0.9756\n",
      "Epoch 50/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0164 - acc: 0.9972 - val_loss: 0.0855 - val_acc: 0.9769\n",
      "Epoch 51/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0158 - acc: 0.9974 - val_loss: 0.0858 - val_acc: 0.9769\n",
      "Epoch 52/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0153 - acc: 0.9976 - val_loss: 0.0862 - val_acc: 0.9761\n",
      "Epoch 53/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0149 - acc: 0.9975 - val_loss: 0.0854 - val_acc: 0.9777\n",
      "Epoch 54/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0143 - acc: 0.9978 - val_loss: 0.0883 - val_acc: 0.9766\n",
      "Epoch 55/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0139 - acc: 0.9981 - val_loss: 0.0867 - val_acc: 0.9765\n",
      "Epoch 56/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0134 - acc: 0.9981 - val_loss: 0.0862 - val_acc: 0.9768\n",
      "Epoch 57/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0130 - acc: 0.9983 - val_loss: 0.0864 - val_acc: 0.9772\n",
      "Epoch 58/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0126 - acc: 0.9984 - val_loss: 0.0867 - val_acc: 0.9771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0121 - acc: 0.9986 - val_loss: 0.0900 - val_acc: 0.9767\n",
      "Epoch 60/1000\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 0.0118 - acc: 0.9986 - val_loss: 0.0889 - val_acc: 0.9770\n",
      "Epoch 61/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0114 - acc: 0.9986 - val_loss: 0.0874 - val_acc: 0.9765\n",
      "Epoch 62/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0113 - acc: 0.9987 - val_loss: 0.0895 - val_acc: 0.9767\n",
      "Epoch 63/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0108 - acc: 0.9989 - val_loss: 0.0899 - val_acc: 0.9765\n",
      "Epoch 64/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0105 - acc: 0.9989 - val_loss: 0.0902 - val_acc: 0.9764\n",
      "Epoch 65/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0102 - acc: 0.9989 - val_loss: 0.0909 - val_acc: 0.9760\n",
      "Epoch 66/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0099 - acc: 0.9990 - val_loss: 0.0896 - val_acc: 0.9765\n",
      "Epoch 67/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0096 - acc: 0.9992 - val_loss: 0.0911 - val_acc: 0.9768\n",
      "Epoch 68/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0093 - acc: 0.9992 - val_loss: 0.0911 - val_acc: 0.9768\n",
      "Epoch 69/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0090 - acc: 0.9993 - val_loss: 0.0917 - val_acc: 0.9769\n",
      "Epoch 70/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0088 - acc: 0.9992 - val_loss: 0.0921 - val_acc: 0.9768\n",
      "Epoch 71/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0086 - acc: 0.9994 - val_loss: 0.0905 - val_acc: 0.9762\n",
      "Epoch 72/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0084 - acc: 0.9993 - val_loss: 0.0925 - val_acc: 0.9763\n",
      "Epoch 73/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0081 - acc: 0.9994 - val_loss: 0.0923 - val_acc: 0.9766\n",
      "Epoch 74/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0079 - acc: 0.9994 - val_loss: 0.0926 - val_acc: 0.9767\n",
      "Epoch 75/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0077 - acc: 0.9994 - val_loss: 0.0945 - val_acc: 0.9770\n",
      "Epoch 76/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0076 - acc: 0.9995 - val_loss: 0.0935 - val_acc: 0.9767\n",
      "Epoch 77/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0074 - acc: 0.9995 - val_loss: 0.0921 - val_acc: 0.9771\n",
      "Epoch 78/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0071 - acc: 0.9996 - val_loss: 0.0929 - val_acc: 0.9767\n",
      "Epoch 79/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0070 - acc: 0.9996 - val_loss: 0.0938 - val_acc: 0.9775\n",
      "Epoch 80/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0068 - acc: 0.9995 - val_loss: 0.0934 - val_acc: 0.9771\n",
      "Epoch 81/1000\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0066 - acc: 0.9997 - val_loss: 0.0948 - val_acc: 0.97710066 - a\n",
      "Epoch 82/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0065 - acc: 0.9996 - val_loss: 0.0953 - val_acc: 0.9764\n",
      "Epoch 83/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.0960 - val_acc: 0.9773\n",
      "Epoch 84/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0061 - acc: 0.9998 - val_loss: 0.0942 - val_acc: 0.9767\n",
      "Epoch 85/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0061 - acc: 0.9998 - val_loss: 0.0958 - val_acc: 0.9768\n",
      "Epoch 86/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0059 - acc: 0.9998 - val_loss: 0.0952 - val_acc: 0.9768\n",
      "Epoch 87/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0057 - acc: 0.9998 - val_loss: 0.0961 - val_acc: 0.9766\n",
      "Epoch 88/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0057 - acc: 0.9998 - val_loss: 0.0961 - val_acc: 0.9769\n",
      "Epoch 89/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0055 - acc: 0.9998 - val_loss: 0.0961 - val_acc: 0.9771\n",
      "Epoch 90/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0054 - acc: 0.9998 - val_loss: 0.0976 - val_acc: 0.9768\n",
      "Epoch 91/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0053 - acc: 0.9998 - val_loss: 0.0964 - val_acc: 0.9768\n",
      "Epoch 92/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0052 - acc: 0.9998 - val_loss: 0.0963 - val_acc: 0.9770\n",
      "Epoch 93/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0051 - acc: 0.9998 - val_loss: 0.0979 - val_acc: 0.9759\n",
      "Epoch 94/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0050 - acc: 0.9999 - val_loss: 0.0974 - val_acc: 0.9766\n",
      "Epoch 95/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0049 - acc: 0.9999 - val_loss: 0.0984 - val_acc: 0.9769\n",
      "Epoch 96/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0048 - acc: 0.9998 - val_loss: 0.0991 - val_acc: 0.9770\n",
      "Epoch 97/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0047 - acc: 0.9999 - val_loss: 0.0992 - val_acc: 0.9764\n",
      "Epoch 98/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0046 - acc: 0.9999 - val_loss: 0.0979 - val_acc: 0.9768\n",
      "Epoch 99/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0045 - acc: 0.9999 - val_loss: 0.1005 - val_acc: 0.9762\n",
      "Epoch 100/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0044 - acc: 0.9999 - val_loss: 0.0992 - val_acc: 0.9763\n",
      "Epoch 101/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0989 - val_acc: 0.9765\n",
      "Epoch 102/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.0991 - val_acc: 0.9765\n",
      "Epoch 103/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 0.1003 - val_acc: 0.9765\n",
      "Epoch 104/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0041 - acc: 0.9999 - val_loss: 0.0998 - val_acc: 0.9758\n",
      "Epoch 105/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1002 - val_acc: 0.9765\n",
      "Epoch 106/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0040 - acc: 0.9999 - val_loss: 0.1009 - val_acc: 0.9769\n",
      "Epoch 107/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9764\n",
      "Epoch 108/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1013 - val_acc: 0.9771\n",
      "Epoch 109/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9766\n",
      "Epoch 110/1000\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1019 - val_acc: 0.9771\n",
      "Epoch 111/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1011 - val_acc: 0.9760\n",
      "Epoch 112/1000\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1017 - val_acc: 0.9763\n",
      "Epoch 113/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9757\n",
      "Epoch 114/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1019 - val_acc: 0.9756\n",
      "Epoch 115/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9765\n",
      "Epoch 116/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1022 - val_acc: 0.9770\n",
      "Epoch 118/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1028 - val_acc: 0.9763\n",
      "Epoch 119/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1027 - val_acc: 0.9764\n",
      "Epoch 120/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1034 - val_acc: 0.9763\n",
      "Epoch 121/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.1039 - val_acc: 0.9769\n",
      "Epoch 122/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9761\n",
      "Epoch 123/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1034 - val_acc: 0.9767\n",
      "Epoch 124/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1031 - val_acc: 0.9762\n",
      "Epoch 125/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1036 - val_acc: 0.9758\n",
      "Epoch 126/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 0.9765\n",
      "Epoch 127/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9765\n",
      "Epoch 128/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 0.9765\n",
      "Epoch 129/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1049 - val_acc: 0.9770\n",
      "Epoch 130/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9759\n",
      "Epoch 131/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1059 - val_acc: 0.9764\n",
      "Epoch 132/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1055 - val_acc: 0.9765\n",
      "Epoch 133/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9764\n",
      "Epoch 134/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1052 - val_acc: 0.9764\n",
      "Epoch 135/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 0.9766\n",
      "Epoch 136/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1056 - val_acc: 0.9762\n",
      "Epoch 137/1000\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1065 - val_acc: 0.9766\n",
      "Epoch 138/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9755\n",
      "Epoch 139/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9764\n",
      "Epoch 140/1000\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1067 - val_acc: 0.9766\n",
      "Epoch 141/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9761\n",
      "Epoch 142/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1065 - val_acc: 0.9763\n",
      "Epoch 143/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1067 - val_acc: 0.9763\n",
      "Epoch 144/1000\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1069 - val_acc: 0.9761\n",
      "Epoch 145/1000\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1068 - val_acc: 0.9760\n",
      "Epoch 146/1000\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1065 - val_acc: 0.9764\n",
      "Epoch 147/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9765\n",
      "Epoch 148/1000\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9760\n",
      "Epoch 149/1000\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9764\n",
      "Epoch 150/1000\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9763\n",
      "Epoch 151/1000\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1083 - val_acc: 0.9760\n",
      "Epoch 152/1000\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9765\n",
      "Epoch 153/1000\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 0.9769\n",
      "Epoch 154/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9764\n",
      "Epoch 155/1000\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9763\n",
      "Epoch 156/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9756\n",
      "Epoch 157/1000\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 0.9759\n",
      "Epoch 158/1000\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9760\n",
      "Epoch 159/1000\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 0.9761\n",
      "Epoch 160/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9762\n",
      "Epoch 161/1000\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 0.9763\n",
      "Epoch 162/1000\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.9760\n",
      "Epoch 163/1000\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1101 - val_acc: 0.9761\n",
      "Epoch 164/1000\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1103 - val_acc: 0.9763\n",
      "Epoch 165/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 0.9763\n",
      "Epoch 166/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9769\n",
      "Epoch 167/1000\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1106 - val_acc: 0.9764\n",
      "Epoch 168/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1102 - val_acc: 0.9764\n",
      "Epoch 169/1000\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1108 - val_acc: 0.9761\n",
      "Epoch 170/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1109 - val_acc: 0.9761\n",
      "Epoch 171/1000\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1110 - val_acc: 0.9762\n",
      "Epoch 172/1000\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1107 - val_acc: 0.9762\n",
      "Epoch 173/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1110 - val_acc: 0.9759\n",
      "Epoch 174/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1111 - val_acc: 0.9759\n",
      "Epoch 175/1000\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1113 - val_acc: 0.9762\n",
      "Epoch 176/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1118 - val_acc: 0.9763\n",
      "Epoch 177/1000\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1121 - val_acc: 0.9761\n",
      "Epoch 178/1000\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1118 - val_acc: 0.9762\n",
      "Epoch 179/1000\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1116 - val_acc: 0.9757\n",
      "Epoch 180/1000\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1122 - val_acc: 0.9763\n",
      "Epoch 181/1000\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9765\n",
      "Epoch 182/1000\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1118 - val_acc: 0.9760\n",
      "Epoch 183/1000\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1121 - val_acc: 0.9756\n",
      "Epoch 184/1000\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1130 - val_acc: 0.9761\n",
      "Epoch 185/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1119 - val_acc: 0.9761\n",
      "Epoch 186/1000\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1124 - val_acc: 0.9760\n",
      "Epoch 187/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1130 - val_acc: 0.9761\n",
      "Epoch 188/1000\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 0.9756\n",
      "Epoch 189/1000\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1136 - val_acc: 0.9765\n",
      "Epoch 190/1000\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1130 - val_acc: 0.9758\n",
      "Epoch 191/1000\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1135 - val_acc: 0.9757\n",
      "Epoch 192/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1137 - val_acc: 0.9763\n",
      "Epoch 193/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1137 - val_acc: 0.9762\n",
      "Epoch 194/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1135 - val_acc: 0.9763\n",
      "Epoch 195/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1139 - val_acc: 0.9755\n",
      "Epoch 196/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1140 - val_acc: 0.9762\n",
      "Epoch 197/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1139 - val_acc: 0.9761\n",
      "Epoch 198/1000\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1139 - val_acc: 0.9761\n",
      "Epoch 199/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1143 - val_acc: 0.9757\n",
      "Epoch 200/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1146 - val_acc: 0.9758\n",
      "Epoch 201/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1142 - val_acc: 0.9756\n",
      "Epoch 202/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1142 - val_acc: 0.9755\n",
      "Epoch 203/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 0.9757\n",
      "Epoch 204/1000\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1144 - val_acc: 0.9759\n",
      "Epoch 205/1000\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1148 - val_acc: 0.9759\n",
      "Epoch 206/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9758\n",
      "Epoch 207/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 0.9759\n",
      "Epoch 208/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 0.9762\n",
      "Epoch 209/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9762\n",
      "Epoch 210/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1151 - val_acc: 0.9757\n",
      "Epoch 211/1000\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 0.9759\n",
      "Epoch 212/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9757\n",
      "Epoch 213/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9761\n",
      "Epoch 214/1000\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1158 - val_acc: 0.9764\n",
      "Epoch 215/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 0.9755\n",
      "Epoch 216/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1160 - val_acc: 0.9758\n",
      "Epoch 217/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1160 - val_acc: 0.9762\n",
      "Epoch 218/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1159 - val_acc: 0.9762\n",
      "Epoch 219/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 0.9760\n",
      "Epoch 220/1000\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9763\n",
      "Epoch 221/1000\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1161 - val_acc: 0.9757\n",
      "Epoch 222/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1161 - val_acc: 0.9758\n",
      "Epoch 223/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1165 - val_acc: 0.9763\n",
      "Epoch 224/1000\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9760\n",
      "Epoch 225/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9762\n",
      "Epoch 226/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1167 - val_acc: 0.9759\n",
      "Epoch 227/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1166 - val_acc: 0.9759\n",
      "Epoch 228/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1171 - val_acc: 0.9758\n",
      "Epoch 229/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1170 - val_acc: 0.9759\n",
      "Epoch 230/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1175 - val_acc: 0.9761\n",
      "Epoch 231/1000\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1176 - val_acc: 0.9762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1177 - val_acc: 0.9764\n",
      "Epoch 233/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1178 - val_acc: 0.9760\n",
      "Epoch 234/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1178 - val_acc: 0.9761\n",
      "Epoch 235/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1176 - val_acc: 0.9763\n",
      "Epoch 236/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1172 - val_acc: 0.9761\n",
      "Epoch 237/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1181 - val_acc: 0.9761\n",
      "Epoch 238/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1179 - val_acc: 0.9758\n",
      "Epoch 239/1000\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1181 - val_acc: 0.9759\n",
      "Epoch 240/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1179 - val_acc: 0.9761\n",
      "Epoch 241/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1181 - val_acc: 0.9758\n",
      "Epoch 242/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1183 - val_acc: 0.9761\n",
      "Epoch 243/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1181 - val_acc: 0.9763\n",
      "Epoch 244/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1185 - val_acc: 0.9758\n",
      "Epoch 245/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1186 - val_acc: 0.9760\n",
      "Epoch 246/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1184 - val_acc: 0.9760\n",
      "Epoch 247/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1190 - val_acc: 0.9762\n",
      "Epoch 248/1000\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1186 - val_acc: 0.9759\n",
      "Epoch 249/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 9.9482e-04 - acc: 1.0000 - val_loss: 0.1185 - val_acc: 0.9760\n",
      "Epoch 250/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 9.8447e-04 - acc: 1.0000 - val_loss: 0.1190 - val_acc: 0.9759\n",
      "Epoch 251/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 9.8575e-04 - acc: 1.0000 - val_loss: 0.1191 - val_acc: 0.9757\n",
      "Epoch 252/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 9.7997e-04 - acc: 1.0000 - val_loss: 0.1195 - val_acc: 0.9762\n",
      "Epoch 253/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 9.7417e-04 - acc: 1.0000 - val_loss: 0.1189 - val_acc: 0.9762\n",
      "Epoch 254/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 9.6685e-04 - acc: 1.0000 - val_loss: 0.1190 - val_acc: 0.9758\n",
      "Epoch 255/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 9.6328e-04 - acc: 1.0000 - val_loss: 0.1194 - val_acc: 0.9759\n",
      "Epoch 256/1000\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 9.5721e-04 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 0.9759\n",
      "Epoch 257/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 9.4972e-04 - acc: 1.0000 - val_loss: 0.1195 - val_acc: 0.9759\n",
      "Epoch 258/1000\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 9.4667e-04 - acc: 1.0000 - val_loss: 0.1193 - val_acc: 0.9759\n",
      "Epoch 259/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 9.4208e-04 - acc: 1.0000 - val_loss: 0.1193 - val_acc: 0.9756\n",
      "Epoch 260/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 9.3253e-04 - acc: 1.0000 - val_loss: 0.1200 - val_acc: 0.9763\n",
      "Epoch 261/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 9.3203e-04 - acc: 1.0000 - val_loss: 0.1196 - val_acc: 0.9759\n",
      "Epoch 262/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 9.2562e-04 - acc: 1.0000 - val_loss: 0.1199 - val_acc: 0.9760\n",
      "Epoch 263/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 9.1836e-04 - acc: 1.0000 - val_loss: 0.1202 - val_acc: 0.9759\n",
      "Epoch 264/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 9.1521e-04 - acc: 1.0000 - val_loss: 0.1200 - val_acc: 0.9756\n",
      "Epoch 265/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 9.1205e-04 - acc: 1.0000 - val_loss: 0.1201 - val_acc: 0.9763\n",
      "Epoch 266/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 9.0502e-04 - acc: 1.0000 - val_loss: 0.1204 - val_acc: 0.9759\n",
      "Epoch 267/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 9.0060e-04 - acc: 1.0000 - val_loss: 0.1206 - val_acc: 0.9757\n",
      "Epoch 268/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 8.9697e-04 - acc: 1.0000 - val_loss: 0.1200 - val_acc: 0.9755\n",
      "Epoch 269/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 8.9080e-04 - acc: 1.0000 - val_loss: 0.1203 - val_acc: 0.9759\n",
      "Epoch 270/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 8.8553e-04 - acc: 1.0000 - val_loss: 0.1206 - val_acc: 0.9760\n",
      "Epoch 271/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 8.8172e-04 - acc: 1.0000 - val_loss: 0.1204 - val_acc: 0.9759\n",
      "Epoch 272/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 8.7597e-04 - acc: 1.0000 - val_loss: 0.1206 - val_acc: 0.9759\n",
      "Epoch 273/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 8.7229e-04 - acc: 1.0000 - val_loss: 0.1204 - val_acc: 0.9759\n",
      "Epoch 274/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 8.6713e-04 - acc: 1.0000 - val_loss: 0.1203 - val_acc: 0.9762\n",
      "Epoch 275/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 8.6165e-04 - acc: 1.0000 - val_loss: 0.1209 - val_acc: 0.9760\n",
      "Epoch 276/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 8.5773e-04 - acc: 1.0000 - val_loss: 0.1209 - val_acc: 0.9760\n",
      "Epoch 277/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 8.5507e-04 - acc: 1.0000 - val_loss: 0.1211 - val_acc: 0.9759\n",
      "Epoch 278/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 8.4872e-04 - acc: 1.0000 - val_loss: 0.1210 - val_acc: 0.9764\n",
      "Epoch 279/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 8.4604e-04 - acc: 1.0000 - val_loss: 0.1212 - val_acc: 0.9759\n",
      "Epoch 280/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 8.3994e-04 - acc: 1.0000 - val_loss: 0.1212 - val_acc: 0.9759\n",
      "Epoch 281/1000\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 8.3313e-04 - acc: 1.0000 - val_loss: 0.1212 - val_acc: 0.9758\n",
      "Epoch 282/1000\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 8.3357e-04 - acc: 1.0000 - val_loss: 0.1211 - val_acc: 0.9762\n",
      "Epoch 283/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 8.2778e-04 - acc: 1.0000 - val_loss: 0.1213 - val_acc: 0.9758\n",
      "Epoch 284/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 8.2238e-04 - acc: 1.0000 - val_loss: 0.1219 - val_acc: 0.9764\n",
      "Epoch 285/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 8.1968e-04 - acc: 1.0000 - val_loss: 0.1215 - val_acc: 0.9757\n",
      "Epoch 286/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 8.1645e-04 - acc: 1.0000 - val_loss: 0.1216 - val_acc: 0.9762\n",
      "Epoch 287/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 8.1364e-04 - acc: 1.0000 - val_loss: 0.1216 - val_acc: 0.9758\n",
      "Epoch 288/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 111us/step - loss: 8.0819e-04 - acc: 1.0000 - val_loss: 0.1216 - val_acc: 0.9759\n",
      "Epoch 289/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 8.0391e-04 - acc: 1.0000 - val_loss: 0.1214 - val_acc: 0.9757\n",
      "Epoch 290/1000\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 7.9966e-04 - acc: 1.0000 - val_loss: 0.1219 - val_acc: 0.9757\n",
      "Epoch 291/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 7.9509e-04 - acc: 1.0000 - val_loss: 0.1217 - val_acc: 0.9756\n",
      "Epoch 292/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 7.9124e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9757\n",
      "Epoch 293/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 7.8924e-04 - acc: 1.0000 - val_loss: 0.1222 - val_acc: 0.9757\n",
      "Epoch 294/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 7.8600e-04 - acc: 1.0000 - val_loss: 0.1220 - val_acc: 0.9757\n",
      "Epoch 295/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 7.8052e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9758\n",
      "Epoch 296/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 7.7590e-04 - acc: 1.0000 - val_loss: 0.1226 - val_acc: 0.9760\n",
      "Epoch 297/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 7.7316e-04 - acc: 1.0000 - val_loss: 0.1221 - val_acc: 0.9759\n",
      "Epoch 298/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 7.7017e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9758\n",
      "Epoch 299/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 7.6642e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9758\n",
      "Epoch 300/1000\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 7.6266e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9760\n",
      "Epoch 301/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 7.6064e-04 - acc: 1.0000 - val_loss: 0.1227 - val_acc: 0.9758\n",
      "Epoch 302/1000\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 7.5582e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9760\n",
      "Epoch 303/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 7.5093e-04 - acc: 1.0000 - val_loss: 0.1227 - val_acc: 0.9760\n",
      "Epoch 304/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 7.4723e-04 - acc: 1.0000 - val_loss: 0.1231 - val_acc: 0.9760\n",
      "Epoch 305/1000\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 7.4596e-04 - acc: 1.0000 - val_loss: 0.1228 - val_acc: 0.9759\n",
      "Epoch 306/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 7.4212e-04 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9759\n",
      "Epoch 307/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 7.3986e-04 - acc: 1.0000 - val_loss: 0.1228 - val_acc: 0.9761\n",
      "Epoch 308/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 7.3564e-04 - acc: 1.0000 - val_loss: 0.1229 - val_acc: 0.9758\n",
      "Epoch 309/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 7.3156e-04 - acc: 1.0000 - val_loss: 0.1228 - val_acc: 0.9757\n",
      "Epoch 310/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 7.2920e-04 - acc: 1.0000 - val_loss: 0.1233 - val_acc: 0.9762\n",
      "Epoch 311/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 7.2396e-04 - acc: 1.0000 - val_loss: 0.1232 - val_acc: 0.9758\n",
      "Epoch 312/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 7.2170e-04 - acc: 1.0000 - val_loss: 0.1232 - val_acc: 0.9758\n",
      "Epoch 313/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 7.1868e-04 - acc: 1.0000 - val_loss: 0.1233 - val_acc: 0.9761\n",
      "Epoch 314/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 7.1442e-04 - acc: 1.0000 - val_loss: 0.1233 - val_acc: 0.9758\n",
      "Epoch 315/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 7.1192e-04 - acc: 1.0000 - val_loss: 0.1234 - val_acc: 0.9758\n",
      "Epoch 316/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 7.0918e-04 - acc: 1.0000 - val_loss: 0.1236 - val_acc: 0.9758\n",
      "Epoch 317/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 7.0707e-04 - acc: 1.0000 - val_loss: 0.1232 - val_acc: 0.9760\n",
      "Epoch 318/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 7.0413e-04 - acc: 1.0000 - val_loss: 0.1235 - val_acc: 0.9759\n",
      "Epoch 319/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 6.9995e-04 - acc: 1.0000 - val_loss: 0.1235 - val_acc: 0.9760\n",
      "Epoch 320/1000\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 6.9803e-04 - acc: 1.0000 - val_loss: 0.1233 - val_acc: 0.9758\n",
      "Epoch 321/1000\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 6.9418e-04 - acc: 1.0000 - val_loss: 0.1235 - val_acc: 0.9760\n",
      "Epoch 322/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 6.9220e-04 - acc: 1.0000 - val_loss: 0.1237 - val_acc: 0.9759\n",
      "Epoch 323/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 6.8678e-04 - acc: 1.0000 - val_loss: 0.1241 - val_acc: 0.9759\n",
      "Epoch 324/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 6.8472e-04 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9760\n",
      "Epoch 325/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 6.8050e-04 - acc: 1.0000 - val_loss: 0.1246 - val_acc: 0.9759\n",
      "Epoch 326/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 6.7934e-04 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9761\n",
      "Epoch 327/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 6.7518e-04 - acc: 1.0000 - val_loss: 0.1243 - val_acc: 0.9758\n",
      "Epoch 328/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 6.7334e-04 - acc: 1.0000 - val_loss: 0.1244 - val_acc: 0.9761\n",
      "Epoch 329/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 6.7198e-04 - acc: 1.0000 - val_loss: 0.1241 - val_acc: 0.9761\n",
      "Epoch 330/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 6.6853e-04 - acc: 1.0000 - val_loss: 0.1241 - val_acc: 0.9757\n",
      "Epoch 331/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 6.6497e-04 - acc: 1.0000 - val_loss: 0.1242 - val_acc: 0.9760\n",
      "Epoch 332/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 6.6264e-04 - acc: 1.0000 - val_loss: 0.1242 - val_acc: 0.9759\n",
      "Epoch 333/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 6.6015e-04 - acc: 1.0000 - val_loss: 0.1245 - val_acc: 0.9755\n",
      "Epoch 334/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 6.5574e-04 - acc: 1.0000 - val_loss: 0.1244 - val_acc: 0.9757\n",
      "Epoch 335/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 6.5432e-04 - acc: 1.0000 - val_loss: 0.1245 - val_acc: 0.9761\n",
      "Epoch 336/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 6.5178e-04 - acc: 1.0000 - val_loss: 0.1244 - val_acc: 0.9761\n",
      "Epoch 337/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 6.4705e-04 - acc: 1.0000 - val_loss: 0.1246 - val_acc: 0.9762\n",
      "Epoch 338/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 6.4471e-04 - acc: 1.0000 - val_loss: 0.1247 - val_acc: 0.9760\n",
      "Epoch 339/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 6.4333e-04 - acc: 1.0000 - val_loss: 0.1249 - val_acc: 0.9760\n",
      "Epoch 340/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 6.4011e-04 - acc: 1.0000 - val_loss: 0.1250 - val_acc: 0.9758\n",
      "Epoch 341/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 6.3675e-04 - acc: 1.0000 - val_loss: 0.1249 - val_acc: 0.9759\n",
      "Epoch 342/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 6.3453e-04 - acc: 1.0000 - val_loss: 0.1250 - val_acc: 0.9759\n",
      "Epoch 343/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 6.3352e-04 - acc: 1.0000 - val_loss: 0.1251 - val_acc: 0.9760\n",
      "Epoch 344/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 114us/step - loss: 6.3066e-04 - acc: 1.0000 - val_loss: 0.1249 - val_acc: 0.9760\n",
      "Epoch 345/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 6.2737e-04 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9757\n",
      "Epoch 346/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 6.2574e-04 - acc: 1.0000 - val_loss: 0.1251 - val_acc: 0.9761\n",
      "Epoch 347/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 6.2192e-04 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9758\n",
      "Epoch 348/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 6.2056e-04 - acc: 1.0000 - val_loss: 0.1251 - val_acc: 0.9763\n",
      "Epoch 349/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 6.1736e-04 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9758\n",
      "Epoch 350/1000\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 6.1604e-04 - acc: 1.0000 - val_loss: 0.1255 - val_acc: 0.9759\n",
      "Epoch 351/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 6.1310e-04 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9760\n",
      "Epoch 352/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 6.1221e-04 - acc: 1.0000 - val_loss: 0.1256 - val_acc: 0.9761\n",
      "Epoch 353/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 6.0810e-04 - acc: 1.0000 - val_loss: 0.1256 - val_acc: 0.9756\n",
      "Epoch 354/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 6.0655e-04 - acc: 1.0000 - val_loss: 0.1256 - val_acc: 0.9758\n",
      "Epoch 355/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 6.0445e-04 - acc: 1.0000 - val_loss: 0.1254 - val_acc: 0.9760\n",
      "Epoch 356/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 6.0126e-04 - acc: 1.0000 - val_loss: 0.1258 - val_acc: 0.9758\n",
      "Epoch 357/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 5.9902e-04 - acc: 1.0000 - val_loss: 0.1256 - val_acc: 0.9761\n",
      "Epoch 358/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 5.9609e-04 - acc: 1.0000 - val_loss: 0.1263 - val_acc: 0.9755\n",
      "Epoch 359/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 5.9533e-04 - acc: 1.0000 - val_loss: 0.1259 - val_acc: 0.9760\n",
      "Epoch 360/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 5.9088e-04 - acc: 1.0000 - val_loss: 0.1259 - val_acc: 0.9761\n",
      "Epoch 361/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 5.9047e-04 - acc: 1.0000 - val_loss: 0.1257 - val_acc: 0.9759\n",
      "Epoch 362/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 5.8705e-04 - acc: 1.0000 - val_loss: 0.1261 - val_acc: 0.9760\n",
      "Epoch 363/1000\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 5.8637e-04 - acc: 1.0000 - val_loss: 0.1260 - val_acc: 0.9763\n",
      "Epoch 364/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 5.8335e-04 - acc: 1.0000 - val_loss: 0.1262 - val_acc: 0.9755\n",
      "Epoch 365/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 5.8099e-04 - acc: 1.0000 - val_loss: 0.1262 - val_acc: 0.9759\n",
      "Epoch 366/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 5.7907e-04 - acc: 1.0000 - val_loss: 0.1261 - val_acc: 0.9756\n",
      "Epoch 367/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 5.7684e-04 - acc: 1.0000 - val_loss: 0.1262 - val_acc: 0.9759\n",
      "Epoch 368/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 5.7469e-04 - acc: 1.0000 - val_loss: 0.1262 - val_acc: 0.9758\n",
      "Epoch 369/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 5.7264e-04 - acc: 1.0000 - val_loss: 0.1264 - val_acc: 0.9760\n",
      "Epoch 370/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 5.7102e-04 - acc: 1.0000 - val_loss: 0.1265 - val_acc: 0.9757\n",
      "Epoch 371/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 5.6779e-04 - acc: 1.0000 - val_loss: 0.1265 - val_acc: 0.9759\n",
      "Epoch 372/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 5.6686e-04 - acc: 1.0000 - val_loss: 0.1264 - val_acc: 0.9755\n",
      "Epoch 373/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 5.6394e-04 - acc: 1.0000 - val_loss: 0.1264 - val_acc: 0.9761\n",
      "Epoch 374/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 5.6132e-04 - acc: 1.0000 - val_loss: 0.1263 - val_acc: 0.9761\n",
      "Epoch 375/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 5.5981e-04 - acc: 1.0000 - val_loss: 0.1265 - val_acc: 0.9759\n",
      "Epoch 376/1000\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 5.5810e-04 - acc: 1.0000 - val_loss: 0.1267 - val_acc: 0.9760\n",
      "Epoch 377/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 5.5577e-04 - acc: 1.0000 - val_loss: 0.1269 - val_acc: 0.9757\n",
      "Epoch 378/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 5.5407e-04 - acc: 1.0000 - val_loss: 0.1269 - val_acc: 0.9756\n",
      "Epoch 379/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 5.5260e-04 - acc: 1.0000 - val_loss: 0.1267 - val_acc: 0.9759\n",
      "Epoch 380/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 5.4930e-04 - acc: 1.0000 - val_loss: 0.1270 - val_acc: 0.9760\n",
      "Epoch 381/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 5.4740e-04 - acc: 1.0000 - val_loss: 0.1267 - val_acc: 0.9759\n",
      "Epoch 382/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 5.4633e-04 - acc: 1.0000 - val_loss: 0.1267 - val_acc: 0.9761\n",
      "Epoch 383/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 5.4415e-04 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9759\n",
      "Epoch 384/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 5.4238e-04 - acc: 1.0000 - val_loss: 0.1268 - val_acc: 0.9756\n",
      "Epoch 385/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 5.4079e-04 - acc: 1.0000 - val_loss: 0.1271 - val_acc: 0.9756\n",
      "Epoch 386/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 5.3898e-04 - acc: 1.0000 - val_loss: 0.1270 - val_acc: 0.9757\n",
      "Epoch 387/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 5.3635e-04 - acc: 1.0000 - val_loss: 0.1272 - val_acc: 0.9757\n",
      "Epoch 388/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 5.3405e-04 - acc: 1.0000 - val_loss: 0.1272 - val_acc: 0.9762\n",
      "Epoch 389/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 5.3327e-04 - acc: 1.0000 - val_loss: 0.1273 - val_acc: 0.9763\n",
      "Epoch 390/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 5.3039e-04 - acc: 1.0000 - val_loss: 0.1273 - val_acc: 0.9762\n",
      "Epoch 391/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 5.2946e-04 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9758\n",
      "Epoch 392/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 5.2733e-04 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9760\n",
      "Epoch 393/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 5.2589e-04 - acc: 1.0000 - val_loss: 0.1276 - val_acc: 0.9761\n",
      "Epoch 394/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 5.2329e-04 - acc: 1.0000 - val_loss: 0.1278 - val_acc: 0.9756\n",
      "Epoch 395/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 5.2159e-04 - acc: 1.0000 - val_loss: 0.1273 - val_acc: 0.9760\n",
      "Epoch 396/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 5.1993e-04 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9763\n",
      "Epoch 397/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 5.1902e-04 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9762\n",
      "Epoch 398/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 5.1637e-04 - acc: 1.0000 - val_loss: 0.1279 - val_acc: 0.9763\n",
      "Epoch 399/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 5.1476e-04 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9761\n",
      "Epoch 400/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 107us/step - loss: 5.1344e-04 - acc: 1.0000 - val_loss: 0.1276 - val_acc: 0.9756\n",
      "Epoch 401/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 5.1060e-04 - acc: 1.0000 - val_loss: 0.1278 - val_acc: 0.9760\n",
      "Epoch 402/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 5.0899e-04 - acc: 1.0000 - val_loss: 0.1280 - val_acc: 0.9756\n",
      "Epoch 403/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 5.0808e-04 - acc: 1.0000 - val_loss: 0.1279 - val_acc: 0.9760\n",
      "Epoch 404/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 5.0586e-04 - acc: 1.0000 - val_loss: 0.1278 - val_acc: 0.9763\n",
      "Epoch 405/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 5.0426e-04 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 0.9757\n",
      "Epoch 406/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 5.0262e-04 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 0.9761\n",
      "Epoch 407/1000\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 5.0143e-04 - acc: 1.0000 - val_loss: 0.1283 - val_acc: 0.9760\n",
      "Epoch 408/1000\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 4.9760e-04 - acc: 1.0000 - val_loss: 0.1278 - val_acc: 0.9761\n",
      "Epoch 409/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 4.9834e-04 - acc: 1.0000 - val_loss: 0.1280 - val_acc: 0.9762\n",
      "Epoch 410/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 4.9621e-04 - acc: 1.0000 - val_loss: 0.1280 - val_acc: 0.9759\n",
      "Epoch 411/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 4.9467e-04 - acc: 1.0000 - val_loss: 0.1283 - val_acc: 0.9759\n",
      "Epoch 412/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 4.9281e-04 - acc: 1.0000 - val_loss: 0.1282 - val_acc: 0.9760\n",
      "Epoch 413/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 4.9158e-04 - acc: 1.0000 - val_loss: 0.1283 - val_acc: 0.9761\n",
      "Epoch 414/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 4.8926e-04 - acc: 1.0000 - val_loss: 0.1284 - val_acc: 0.9761\n",
      "Epoch 415/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 4.8833e-04 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 0.9761\n",
      "Epoch 416/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 4.8653e-04 - acc: 1.0000 - val_loss: 0.1283 - val_acc: 0.9759\n",
      "Epoch 417/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 4.8374e-04 - acc: 1.0000 - val_loss: 0.1288 - val_acc: 0.9760\n",
      "Epoch 418/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 4.8296e-04 - acc: 1.0000 - val_loss: 0.1287 - val_acc: 0.9760\n",
      "Epoch 419/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 4.8237e-04 - acc: 1.0000 - val_loss: 0.1283 - val_acc: 0.9760\n",
      "Epoch 420/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 4.8037e-04 - acc: 1.0000 - val_loss: 0.1286 - val_acc: 0.9759\n",
      "Epoch 421/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 4.7723e-04 - acc: 1.0000 - val_loss: 0.1286 - val_acc: 0.9763\n",
      "Epoch 422/1000\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 4.7708e-04 - acc: 1.0000 - val_loss: 0.1285 - val_acc: 0.9757\n",
      "Epoch 423/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 4.7598e-04 - acc: 1.0000 - val_loss: 0.1288 - val_acc: 0.9759\n",
      "Epoch 424/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 4.7378e-04 - acc: 1.0000 - val_loss: 0.1288 - val_acc: 0.9759\n",
      "Epoch 425/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 4.7235e-04 - acc: 1.0000 - val_loss: 0.1289 - val_acc: 0.9759\n",
      "Epoch 426/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 4.7101e-04 - acc: 1.0000 - val_loss: 0.1287 - val_acc: 0.9761\n",
      "Epoch 427/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 4.6954e-04 - acc: 1.0000 - val_loss: 0.1287 - val_acc: 0.9759\n",
      "Epoch 428/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 4.6825e-04 - acc: 1.0000 - val_loss: 0.1292 - val_acc: 0.9757\n",
      "Epoch 429/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 4.6730e-04 - acc: 1.0000 - val_loss: 0.1289 - val_acc: 0.9763\n",
      "Epoch 430/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 4.6577e-04 - acc: 1.0000 - val_loss: 0.1293 - val_acc: 0.9758\n",
      "Epoch 431/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 4.6428e-04 - acc: 1.0000 - val_loss: 0.1290 - val_acc: 0.9760\n",
      "Epoch 432/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 4.6255e-04 - acc: 1.0000 - val_loss: 0.1291 - val_acc: 0.9761\n",
      "Epoch 433/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 4.6081e-04 - acc: 1.0000 - val_loss: 0.1290 - val_acc: 0.9760\n",
      "Epoch 434/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 4.5955e-04 - acc: 1.0000 - val_loss: 0.1293 - val_acc: 0.9759\n",
      "Epoch 435/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 4.5769e-04 - acc: 1.0000 - val_loss: 0.1293 - val_acc: 0.9762\n",
      "Epoch 436/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 4.5666e-04 - acc: 1.0000 - val_loss: 0.1296 - val_acc: 0.9758\n",
      "Epoch 437/1000\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 4.5545e-04 - acc: 1.0000 - val_loss: 0.1294 - val_acc: 0.9759\n",
      "Epoch 438/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 4.5389e-04 - acc: 1.0000 - val_loss: 0.1292 - val_acc: 0.9760\n",
      "Epoch 439/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 4.5232e-04 - acc: 1.0000 - val_loss: 0.1295 - val_acc: 0.9761\n",
      "Epoch 440/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 4.5166e-04 - acc: 1.0000 - val_loss: 0.1295 - val_acc: 0.9759\n",
      "Epoch 441/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 4.5018e-04 - acc: 1.0000 - val_loss: 0.1293 - val_acc: 0.9762\n",
      "Epoch 442/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 4.4848e-04 - acc: 1.0000 - val_loss: 0.1297 - val_acc: 0.9763\n",
      "Epoch 443/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 4.4722e-04 - acc: 1.0000 - val_loss: 0.1295 - val_acc: 0.9760\n",
      "Epoch 444/1000\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 4.4561e-04 - acc: 1.0000 - val_loss: 0.1296 - val_acc: 0.9759\n",
      "Epoch 445/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 4.4494e-04 - acc: 1.0000 - val_loss: 0.1294 - val_acc: 0.9761\n",
      "Epoch 446/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 4.4349e-04 - acc: 1.0000 - val_loss: 0.1297 - val_acc: 0.9759\n",
      "Epoch 447/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 4.4162e-04 - acc: 1.0000 - val_loss: 0.1298 - val_acc: 0.9756\n",
      "Epoch 448/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 4.4089e-04 - acc: 1.0000 - val_loss: 0.1299 - val_acc: 0.9759\n",
      "Epoch 449/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 4.3893e-04 - acc: 1.0000 - val_loss: 0.1298 - val_acc: 0.9759\n",
      "Epoch 450/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 4.3755e-04 - acc: 1.0000 - val_loss: 0.1298 - val_acc: 0.9759\n",
      "Epoch 451/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 4.3697e-04 - acc: 1.0000 - val_loss: 0.1299 - val_acc: 0.9761\n",
      "Epoch 452/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 4.3579e-04 - acc: 1.0000 - val_loss: 0.1297 - val_acc: 0.9761\n",
      "Epoch 453/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 4.3461e-04 - acc: 1.0000 - val_loss: 0.1299 - val_acc: 0.9759\n",
      "Epoch 454/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 4.3260e-04 - acc: 1.0000 - val_loss: 0.1300 - val_acc: 0.9758\n",
      "Epoch 455/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 4.3176e-04 - acc: 1.0000 - val_loss: 0.1297 - val_acc: 0.9759\n",
      "Epoch 456/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 105us/step - loss: 4.3051e-04 - acc: 1.0000 - val_loss: 0.1299 - val_acc: 0.9757\n",
      "Epoch 457/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 4.2940e-04 - acc: 1.0000 - val_loss: 0.1300 - val_acc: 0.9759\n",
      "Epoch 458/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 4.2809e-04 - acc: 1.0000 - val_loss: 0.1300 - val_acc: 0.9760\n",
      "Epoch 459/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 4.2611e-04 - acc: 1.0000 - val_loss: 0.1305 - val_acc: 0.9756\n",
      "Epoch 460/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 4.2525e-04 - acc: 1.0000 - val_loss: 0.1299 - val_acc: 0.9764\n",
      "Epoch 461/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 4.2376e-04 - acc: 1.0000 - val_loss: 0.1301 - val_acc: 0.9759\n",
      "Epoch 462/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 4.2310e-04 - acc: 1.0000 - val_loss: 0.1300 - val_acc: 0.9760\n",
      "Epoch 463/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 4.2081e-04 - acc: 1.0000 - val_loss: 0.1302 - val_acc: 0.9758\n",
      "Epoch 464/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 4.2094e-04 - acc: 1.0000 - val_loss: 0.1301 - val_acc: 0.9760\n",
      "Epoch 465/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 4.1885e-04 - acc: 1.0000 - val_loss: 0.1304 - val_acc: 0.9760\n",
      "Epoch 466/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 4.1772e-04 - acc: 1.0000 - val_loss: 0.1307 - val_acc: 0.9761\n",
      "Epoch 467/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 4.1708e-04 - acc: 1.0000 - val_loss: 0.1302 - val_acc: 0.9760\n",
      "Epoch 468/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 4.1620e-04 - acc: 1.0000 - val_loss: 0.1305 - val_acc: 0.9760\n",
      "Epoch 469/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 4.1459e-04 - acc: 1.0000 - val_loss: 0.1305 - val_acc: 0.9761\n",
      "Epoch 470/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 4.1336e-04 - acc: 1.0000 - val_loss: 0.1305 - val_acc: 0.9761\n",
      "Epoch 471/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 4.1212e-04 - acc: 1.0000 - val_loss: 0.1305 - val_acc: 0.9760\n",
      "Epoch 472/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 4.1158e-04 - acc: 1.0000 - val_loss: 0.1305 - val_acc: 0.9759\n",
      "Epoch 473/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 4.1021e-04 - acc: 1.0000 - val_loss: 0.1308 - val_acc: 0.9760\n",
      "Epoch 474/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 4.0926e-04 - acc: 1.0000 - val_loss: 0.1306 - val_acc: 0.9759\n",
      "Epoch 475/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 4.0754e-04 - acc: 1.0000 - val_loss: 0.1308 - val_acc: 0.9760\n",
      "Epoch 476/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 4.0687e-04 - acc: 1.0000 - val_loss: 0.1307 - val_acc: 0.9762\n",
      "Epoch 477/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 4.0521e-04 - acc: 1.0000 - val_loss: 0.1307 - val_acc: 0.9760\n",
      "Epoch 478/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 4.0460e-04 - acc: 1.0000 - val_loss: 0.1309 - val_acc: 0.9759\n",
      "Epoch 479/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 4.0308e-04 - acc: 1.0000 - val_loss: 0.1309 - val_acc: 0.9758\n",
      "Epoch 480/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 4.0208e-04 - acc: 1.0000 - val_loss: 0.1307 - val_acc: 0.9759\n",
      "Epoch 481/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 4.0042e-04 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9759\n",
      "Epoch 482/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 4.0034e-04 - acc: 1.0000 - val_loss: 0.1309 - val_acc: 0.9760\n",
      "Epoch 483/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.9896e-04 - acc: 1.0000 - val_loss: 0.1310 - val_acc: 0.9757\n",
      "Epoch 484/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.9778e-04 - acc: 1.0000 - val_loss: 0.1310 - val_acc: 0.9759\n",
      "Epoch 485/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 3.9708e-04 - acc: 1.0000 - val_loss: 0.1310 - val_acc: 0.9758\n",
      "Epoch 486/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.9582e-04 - acc: 1.0000 - val_loss: 0.1312 - val_acc: 0.9760\n",
      "Epoch 487/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 3.9361e-04 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9760\n",
      "Epoch 488/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.9323e-04 - acc: 1.0000 - val_loss: 0.1313 - val_acc: 0.9760\n",
      "Epoch 489/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.9267e-04 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9759\n",
      "Epoch 490/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 3.9144e-04 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9758\n",
      "Epoch 491/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 3.8979e-04 - acc: 1.0000 - val_loss: 0.1312 - val_acc: 0.9756\n",
      "Epoch 492/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.8935e-04 - acc: 1.0000 - val_loss: 0.1313 - val_acc: 0.9758\n",
      "Epoch 493/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.8824e-04 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 0.9760\n",
      "Epoch 494/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 3.8705e-04 - acc: 1.0000 - val_loss: 0.1315 - val_acc: 0.9761\n",
      "Epoch 495/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.8613e-04 - acc: 1.0000 - val_loss: 0.1313 - val_acc: 0.9760\n",
      "Epoch 496/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.8420e-04 - acc: 1.0000 - val_loss: 0.1313 - val_acc: 0.9759\n",
      "Epoch 497/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.8434e-04 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 0.9759\n",
      "Epoch 498/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 3.8294e-04 - acc: 1.0000 - val_loss: 0.1316 - val_acc: 0.9758\n",
      "Epoch 499/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.8205e-04 - acc: 1.0000 - val_loss: 0.1316 - val_acc: 0.9759\n",
      "Epoch 500/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.8030e-04 - acc: 1.0000 - val_loss: 0.1318 - val_acc: 0.9760\n",
      "Epoch 501/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.8025e-04 - acc: 1.0000 - val_loss: 0.1317 - val_acc: 0.9760\n",
      "Epoch 502/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.7928e-04 - acc: 1.0000 - val_loss: 0.1315 - val_acc: 0.9759\n",
      "Epoch 503/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 3.7814e-04 - acc: 1.0000 - val_loss: 0.1316 - val_acc: 0.9761\n",
      "Epoch 504/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.7709e-04 - acc: 1.0000 - val_loss: 0.1318 - val_acc: 0.9760\n",
      "Epoch 505/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.7587e-04 - acc: 1.0000 - val_loss: 0.1316 - val_acc: 0.9759\n",
      "Epoch 506/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.7541e-04 - acc: 1.0000 - val_loss: 0.1318 - val_acc: 0.9759\n",
      "Epoch 507/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 3.7363e-04 - acc: 1.0000 - val_loss: 0.1317 - val_acc: 0.9759\n",
      "Epoch 508/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 3.7297e-04 - acc: 1.0000 - val_loss: 0.1317 - val_acc: 0.9761\n",
      "Epoch 509/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 3.7208e-04 - acc: 1.0000 - val_loss: 0.1319 - val_acc: 0.9759\n",
      "Epoch 510/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 3.7079e-04 - acc: 1.0000 - val_loss: 0.1321 - val_acc: 0.9759\n",
      "Epoch 511/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.6989e-04 - acc: 1.0000 - val_loss: 0.1320 - val_acc: 0.9760\n",
      "Epoch 512/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.6919e-04 - acc: 1.0000 - val_loss: 0.1320 - val_acc: 0.9758\n",
      "Epoch 513/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.6866e-04 - acc: 1.0000 - val_loss: 0.1318 - val_acc: 0.9758\n",
      "Epoch 514/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.6703e-04 - acc: 1.0000 - val_loss: 0.1318 - val_acc: 0.9763\n",
      "Epoch 515/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.6620e-04 - acc: 1.0000 - val_loss: 0.1320 - val_acc: 0.9760\n",
      "Epoch 516/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 3.6523e-04 - acc: 1.0000 - val_loss: 0.1322 - val_acc: 0.9760\n",
      "Epoch 517/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 3.6459e-04 - acc: 1.0000 - val_loss: 0.1320 - val_acc: 0.9758\n",
      "Epoch 518/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.6371e-04 - acc: 1.0000 - val_loss: 0.1323 - val_acc: 0.9760\n",
      "Epoch 519/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.6300e-04 - acc: 1.0000 - val_loss: 0.1321 - val_acc: 0.9760\n",
      "Epoch 520/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 3.6188e-04 - acc: 1.0000 - val_loss: 0.1323 - val_acc: 0.9759\n",
      "Epoch 521/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.6091e-04 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 0.9759\n",
      "Epoch 522/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.5977e-04 - acc: 1.0000 - val_loss: 0.1324 - val_acc: 0.9759\n",
      "Epoch 523/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.5908e-04 - acc: 1.0000 - val_loss: 0.1323 - val_acc: 0.9758\n",
      "Epoch 524/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.5835e-04 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 0.9760\n",
      "Epoch 525/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.5770e-04 - acc: 1.0000 - val_loss: 0.1324 - val_acc: 0.9758\n",
      "Epoch 526/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 3.5672e-04 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 0.9761\n",
      "Epoch 527/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 3.5520e-04 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 0.9759\n",
      "Epoch 528/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.5487e-04 - acc: 1.0000 - val_loss: 0.1328 - val_acc: 0.9759\n",
      "Epoch 529/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.5389e-04 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9760\n",
      "Epoch 530/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.5320e-04 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9762\n",
      "Epoch 531/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.5228e-04 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9759\n",
      "Epoch 532/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 3.5102e-04 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9761\n",
      "Epoch 533/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 3.5028e-04 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9759\n",
      "Epoch 534/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.4964e-04 - acc: 1.0000 - val_loss: 0.1328 - val_acc: 0.9758\n",
      "Epoch 535/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.4862e-04 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9759\n",
      "Epoch 536/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.4802e-04 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9761\n",
      "Epoch 537/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 3.4690e-04 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9760\n",
      "Epoch 538/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 3.4621e-04 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9762\n",
      "Epoch 539/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.4523e-04 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9758\n",
      "Epoch 540/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.4427e-04 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9761\n",
      "Epoch 541/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 3.4372e-04 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9759\n",
      "Epoch 542/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.4279e-04 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9760\n",
      "Epoch 543/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.4208e-04 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9758\n",
      "Epoch 544/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.4132e-04 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9760\n",
      "Epoch 545/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.4031e-04 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9759\n",
      "Epoch 546/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 3.3948e-04 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9760\n",
      "Epoch 547/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.3898e-04 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9760\n",
      "Epoch 548/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.3823e-04 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9759\n",
      "Epoch 549/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.3728e-04 - acc: 1.0000 - val_loss: 0.1332 - val_acc: 0.9759\n",
      "Epoch 550/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 3.3640e-04 - acc: 1.0000 - val_loss: 0.1332 - val_acc: 0.9758\n",
      "Epoch 551/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 3.3546e-04 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9758\n",
      "Epoch 552/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.3431e-04 - acc: 1.0000 - val_loss: 0.1332 - val_acc: 0.9759\n",
      "Epoch 553/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.3407e-04 - acc: 1.0000 - val_loss: 0.1334 - val_acc: 0.9759\n",
      "Epoch 554/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.3349e-04 - acc: 1.0000 - val_loss: 0.1334 - val_acc: 0.9760\n",
      "Epoch 555/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.3199e-04 - acc: 1.0000 - val_loss: 0.1333 - val_acc: 0.9758\n",
      "Epoch 556/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 3.3202e-04 - acc: 1.0000 - val_loss: 0.1332 - val_acc: 0.9757\n",
      "Epoch 557/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 3.3063e-04 - acc: 1.0000 - val_loss: 0.1333 - val_acc: 0.9759\n",
      "Epoch 558/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.3011e-04 - acc: 1.0000 - val_loss: 0.1332 - val_acc: 0.9759\n",
      "Epoch 559/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 3.2947e-04 - acc: 1.0000 - val_loss: 0.1332 - val_acc: 0.9759\n",
      "Epoch 560/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.2853e-04 - acc: 1.0000 - val_loss: 0.1335 - val_acc: 0.9760\n",
      "Epoch 561/1000\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 3.2794e-04 - acc: 1.0000 - val_loss: 0.1336 - val_acc: 0.9760\n",
      "Epoch 562/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 3.2695e-04 - acc: 1.0000 - val_loss: 0.1336 - val_acc: 0.9760\n",
      "Epoch 563/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 3.2626e-04 - acc: 1.0000 - val_loss: 0.1334 - val_acc: 0.9759\n",
      "Epoch 564/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 3.2552e-04 - acc: 1.0000 - val_loss: 0.1335 - val_acc: 0.9758\n",
      "Epoch 565/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 3.2432e-04 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9761\n",
      "Epoch 566/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 3.2407e-04 - acc: 1.0000 - val_loss: 0.1339 - val_acc: 0.9759\n",
      "Epoch 567/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 3.2307e-04 - acc: 1.0000 - val_loss: 0.1334 - val_acc: 0.9759\n",
      "Epoch 568/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 111us/step - loss: 3.2262e-04 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9759\n",
      "Epoch 569/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 3.2178e-04 - acc: 1.0000 - val_loss: 0.1336 - val_acc: 0.9760\n",
      "Epoch 570/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 3.2086e-04 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9757\n",
      "Epoch 571/1000\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 3.2055e-04 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9760\n",
      "Epoch 572/1000\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 3.1976e-04 - acc: 1.0000 - val_loss: 0.1338 - val_acc: 0.9761\n",
      "Epoch 573/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 3.1884e-04 - acc: 1.0000 - val_loss: 0.1339 - val_acc: 0.9759\n",
      "Epoch 574/1000\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 3.1820e-04 - acc: 1.0000 - val_loss: 0.1339 - val_acc: 0.9762\n",
      "Epoch 575/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 3.1771e-04 - acc: 1.0000 - val_loss: 0.1340 - val_acc: 0.9760\n",
      "Epoch 576/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 3.1609e-04 - acc: 1.0000 - val_loss: 0.1341 - val_acc: 0.9758\n",
      "Epoch 577/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 3.1598e-04 - acc: 1.0000 - val_loss: 0.1340 - val_acc: 0.9760\n",
      "Epoch 578/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 3.1532e-04 - acc: 1.0000 - val_loss: 0.1339 - val_acc: 0.9759\n",
      "Epoch 579/1000\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 3.1488e-04 - acc: 1.0000 - val_loss: 0.1341 - val_acc: 0.9757\n",
      "Epoch 580/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 3.1340e-04 - acc: 1.0000 - val_loss: 0.1341 - val_acc: 0.9759\n",
      "Epoch 581/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 3.1352e-04 - acc: 1.0000 - val_loss: 0.1343 - val_acc: 0.9758\n",
      "Epoch 582/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 3.1257e-04 - acc: 1.0000 - val_loss: 0.1340 - val_acc: 0.9756\n",
      "Epoch 583/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 3.1150e-04 - acc: 1.0000 - val_loss: 0.1343 - val_acc: 0.9759\n",
      "Epoch 584/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 3.1119e-04 - acc: 1.0000 - val_loss: 0.1341 - val_acc: 0.9760\n",
      "Epoch 585/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 3.1055e-04 - acc: 1.0000 - val_loss: 0.1343 - val_acc: 0.9757\n",
      "Epoch 586/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 3.0976e-04 - acc: 1.0000 - val_loss: 0.1344 - val_acc: 0.9761\n",
      "Epoch 587/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 3.0870e-04 - acc: 1.0000 - val_loss: 0.1343 - val_acc: 0.9758\n",
      "Epoch 588/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 3.0846e-04 - acc: 1.0000 - val_loss: 0.1344 - val_acc: 0.9761\n",
      "Epoch 589/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 3.0800e-04 - acc: 1.0000 - val_loss: 0.1344 - val_acc: 0.9760\n",
      "Epoch 590/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 3.0690e-04 - acc: 1.0000 - val_loss: 0.1342 - val_acc: 0.9760\n",
      "Epoch 591/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 3.0607e-04 - acc: 1.0000 - val_loss: 0.1345 - val_acc: 0.9760\n",
      "Epoch 592/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 3.0585e-04 - acc: 1.0000 - val_loss: 0.1343 - val_acc: 0.9757\n",
      "Epoch 593/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 3.0473e-04 - acc: 1.0000 - val_loss: 0.1346 - val_acc: 0.9762\n",
      "Epoch 594/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 3.0478e-04 - acc: 1.0000 - val_loss: 0.1346 - val_acc: 0.9759\n",
      "Epoch 595/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 3.0350e-04 - acc: 1.0000 - val_loss: 0.1346 - val_acc: 0.9756\n",
      "Epoch 596/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 3.0288e-04 - acc: 1.0000 - val_loss: 0.1344 - val_acc: 0.9760\n",
      "Epoch 597/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 3.0247e-04 - acc: 1.0000 - val_loss: 0.1348 - val_acc: 0.9758\n",
      "Epoch 598/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 3.0186e-04 - acc: 1.0000 - val_loss: 0.1346 - val_acc: 0.9758\n",
      "Epoch 599/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 3.0109e-04 - acc: 1.0000 - val_loss: 0.1345 - val_acc: 0.9760\n",
      "Epoch 600/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 3.0013e-04 - acc: 1.0000 - val_loss: 0.1346 - val_acc: 0.9759\n",
      "Epoch 601/1000\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 2.9916e-04 - acc: 1.0000 - val_loss: 0.1347 - val_acc: 0.9757\n",
      "Epoch 602/1000\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 2.9906e-04 - acc: 1.0000 - val_loss: 0.1347 - val_acc: 0.9758\n",
      "Epoch 603/1000\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 2.9850e-04 - acc: 1.0000 - val_loss: 0.1347 - val_acc: 0.9761\n",
      "Epoch 604/1000\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 2.9765e-04 - acc: 1.0000 - val_loss: 0.1348 - val_acc: 0.9758\n",
      "Epoch 605/1000\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 2.9738e-04 - acc: 1.0000 - val_loss: 0.1347 - val_acc: 0.9758\n",
      "Epoch 606/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 2.9655e-04 - acc: 1.0000 - val_loss: 0.1349 - val_acc: 0.9759\n",
      "Epoch 607/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 2.9610e-04 - acc: 1.0000 - val_loss: 0.1349 - val_acc: 0.9759\n",
      "Epoch 608/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 2.9537e-04 - acc: 1.0000 - val_loss: 0.1348 - val_acc: 0.9760\n",
      "Epoch 609/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 2.9481e-04 - acc: 1.0000 - val_loss: 0.1349 - val_acc: 0.9761\n",
      "Epoch 610/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 2.9401e-04 - acc: 1.0000 - val_loss: 0.1347 - val_acc: 0.9758\n",
      "Epoch 611/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 2.9345e-04 - acc: 1.0000 - val_loss: 0.1348 - val_acc: 0.9757\n",
      "Epoch 612/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 2.9289e-04 - acc: 1.0000 - val_loss: 0.1351 - val_acc: 0.9761\n",
      "Epoch 613/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 2.9231e-04 - acc: 1.0000 - val_loss: 0.1350 - val_acc: 0.9757\n",
      "Epoch 614/1000\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 2.9131e-04 - acc: 1.0000 - val_loss: 0.1351 - val_acc: 0.9758\n",
      "Epoch 615/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 2.9113e-04 - acc: 1.0000 - val_loss: 0.1350 - val_acc: 0.9760\n",
      "Epoch 616/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 2.9047e-04 - acc: 1.0000 - val_loss: 0.1351 - val_acc: 0.9760\n",
      "Epoch 617/1000\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 2.8957e-04 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 0.9759\n",
      "Epoch 618/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 2.8906e-04 - acc: 1.0000 - val_loss: 0.1354 - val_acc: 0.9760\n",
      "Epoch 619/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 2.8887e-04 - acc: 1.0000 - val_loss: 0.1351 - val_acc: 0.9757\n",
      "Epoch 620/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 2.8794e-04 - acc: 1.0000 - val_loss: 0.1351 - val_acc: 0.9757\n",
      "Epoch 621/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 2.8717e-04 - acc: 1.0000 - val_loss: 0.1350 - val_acc: 0.9758\n",
      "Epoch 622/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 2.8700e-04 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 0.9761\n",
      "Epoch 623/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 2.8617e-04 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 0.9758\n",
      "Epoch 624/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 112us/step - loss: 2.8547e-04 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 0.9757\n",
      "Epoch 625/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 2.8537e-04 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 0.9762\n",
      "Epoch 626/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.8449e-04 - acc: 1.0000 - val_loss: 0.1354 - val_acc: 0.9760\n",
      "Epoch 627/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.8398e-04 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 0.9759\n",
      "Epoch 628/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.8312e-04 - acc: 1.0000 - val_loss: 0.1352 - val_acc: 0.9761\n",
      "Epoch 629/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.8277e-04 - acc: 1.0000 - val_loss: 0.1352 - val_acc: 0.9759\n",
      "Epoch 630/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.8239e-04 - acc: 1.0000 - val_loss: 0.1354 - val_acc: 0.9761\n",
      "Epoch 631/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.8153e-04 - acc: 1.0000 - val_loss: 0.1352 - val_acc: 0.9760\n",
      "Epoch 632/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 2.8095e-04 - acc: 1.0000 - val_loss: 0.1356 - val_acc: 0.9758\n",
      "Epoch 633/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 2.8047e-04 - acc: 1.0000 - val_loss: 0.1355 - val_acc: 0.9762\n",
      "Epoch 634/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 2.8004e-04 - acc: 1.0000 - val_loss: 0.1355 - val_acc: 0.9762\n",
      "Epoch 635/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 2.7935e-04 - acc: 1.0000 - val_loss: 0.1356 - val_acc: 0.9759\n",
      "Epoch 636/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 2.7882e-04 - acc: 1.0000 - val_loss: 0.1357 - val_acc: 0.9760\n",
      "Epoch 637/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 2.7791e-04 - acc: 1.0000 - val_loss: 0.1355 - val_acc: 0.9760\n",
      "Epoch 638/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 2.7763e-04 - acc: 1.0000 - val_loss: 0.1356 - val_acc: 0.9760\n",
      "Epoch 639/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 2.7703e-04 - acc: 1.0000 - val_loss: 0.1357 - val_acc: 0.9760 acc:\n",
      "Epoch 640/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 2.7657e-04 - acc: 1.0000 - val_loss: 0.1357 - val_acc: 0.9758\n",
      "Epoch 641/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 2.7600e-04 - acc: 1.0000 - val_loss: 0.1358 - val_acc: 0.9760\n",
      "Epoch 642/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 2.7527e-04 - acc: 1.0000 - val_loss: 0.1358 - val_acc: 0.9761\n",
      "Epoch 643/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 2.7473e-04 - acc: 1.0000 - val_loss: 0.1356 - val_acc: 0.9758\n",
      "Epoch 644/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 2.7382e-04 - acc: 1.0000 - val_loss: 0.1358 - val_acc: 0.9760\n",
      "Epoch 645/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 2.7396e-04 - acc: 1.0000 - val_loss: 0.1359 - val_acc: 0.9763\n",
      "Epoch 646/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.7300e-04 - acc: 1.0000 - val_loss: 0.1359 - val_acc: 0.9761\n",
      "Epoch 647/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.7261e-04 - acc: 1.0000 - val_loss: 0.1359 - val_acc: 0.9758\n",
      "Epoch 648/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.7215e-04 - acc: 1.0000 - val_loss: 0.1359 - val_acc: 0.9759\n",
      "Epoch 649/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.7144e-04 - acc: 1.0000 - val_loss: 0.1361 - val_acc: 0.9761\n",
      "Epoch 650/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 2.7096e-04 - acc: 1.0000 - val_loss: 0.1360 - val_acc: 0.9758\n",
      "Epoch 651/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 2.7062e-04 - acc: 1.0000 - val_loss: 0.1360 - val_acc: 0.9759\n",
      "Epoch 652/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 2.6976e-04 - acc: 1.0000 - val_loss: 0.1360 - val_acc: 0.9761\n",
      "Epoch 653/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 2.6946e-04 - acc: 1.0000 - val_loss: 0.1360 - val_acc: 0.9759\n",
      "Epoch 654/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 2.6891e-04 - acc: 1.0000 - val_loss: 0.1361 - val_acc: 0.9759\n",
      "Epoch 655/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.6827e-04 - acc: 1.0000 - val_loss: 0.1359 - val_acc: 0.9759\n",
      "Epoch 656/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 2.6798e-04 - acc: 1.0000 - val_loss: 0.1360 - val_acc: 0.9759\n",
      "Epoch 657/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 2.6749e-04 - acc: 1.0000 - val_loss: 0.1361 - val_acc: 0.9760\n",
      "Epoch 658/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 2.6683e-04 - acc: 1.0000 - val_loss: 0.1362 - val_acc: 0.9761\n",
      "Epoch 659/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 2.6613e-04 - acc: 1.0000 - val_loss: 0.1363 - val_acc: 0.9759\n",
      "Epoch 660/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 2.6580e-04 - acc: 1.0000 - val_loss: 0.1362 - val_acc: 0.9761\n",
      "Epoch 661/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.6521e-04 - acc: 1.0000 - val_loss: 0.1364 - val_acc: 0.9761\n",
      "Epoch 662/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.6460e-04 - acc: 1.0000 - val_loss: 0.1361 - val_acc: 0.9758\n",
      "Epoch 663/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 2.6416e-04 - acc: 1.0000 - val_loss: 0.1364 - val_acc: 0.9759\n",
      "Epoch 664/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 2.6373e-04 - acc: 1.0000 - val_loss: 0.1362 - val_acc: 0.9758\n",
      "Epoch 665/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 2.6343e-04 - acc: 1.0000 - val_loss: 0.1364 - val_acc: 0.9760\n",
      "Epoch 666/1000\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 2.6219e-04 - acc: 1.0000 - val_loss: 0.1364 - val_acc: 0.9759\n",
      "Epoch 667/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 2.6230e-04 - acc: 1.0000 - val_loss: 0.1365 - val_acc: 0.9762\n",
      "Epoch 668/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 2.6172e-04 - acc: 1.0000 - val_loss: 0.1365 - val_acc: 0.9763\n",
      "Epoch 669/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.6122e-04 - acc: 1.0000 - val_loss: 0.1366 - val_acc: 0.9761\n",
      "Epoch 670/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 2.6074e-04 - acc: 1.0000 - val_loss: 0.1364 - val_acc: 0.9758\n",
      "Epoch 671/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 2.6030e-04 - acc: 1.0000 - val_loss: 0.1364 - val_acc: 0.9760\n",
      "Epoch 672/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 2.5962e-04 - acc: 1.0000 - val_loss: 0.1365 - val_acc: 0.9762\n",
      "Epoch 673/1000\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 2.5923e-04 - acc: 1.0000 - val_loss: 0.1365 - val_acc: 0.9761\n",
      "Epoch 674/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 2.5881e-04 - acc: 1.0000 - val_loss: 0.1364 - val_acc: 0.9758\n",
      "Epoch 675/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.5819e-04 - acc: 1.0000 - val_loss: 0.1366 - val_acc: 0.9761\n",
      "Epoch 676/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.5770e-04 - acc: 1.0000 - val_loss: 0.1363 - val_acc: 0.9759\n",
      "Epoch 677/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.5735e-04 - acc: 1.0000 - val_loss: 0.1366 - val_acc: 0.9761\n",
      "Epoch 678/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.5664e-04 - acc: 1.0000 - val_loss: 0.1365 - val_acc: 0.9757\n",
      "Epoch 679/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.5613e-04 - acc: 1.0000 - val_loss: 0.1367 - val_acc: 0.9761\n",
      "Epoch 680/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.5591e-04 - acc: 1.0000 - val_loss: 0.1367 - val_acc: 0.9760\n",
      "Epoch 681/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.5514e-04 - acc: 1.0000 - val_loss: 0.1371 - val_acc: 0.9761\n",
      "Epoch 682/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.5497e-04 - acc: 1.0000 - val_loss: 0.1367 - val_acc: 0.9760\n",
      "Epoch 683/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.5442e-04 - acc: 1.0000 - val_loss: 0.1368 - val_acc: 0.9761\n",
      "Epoch 684/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.5398e-04 - acc: 1.0000 - val_loss: 0.1369 - val_acc: 0.9760\n",
      "Epoch 685/1000\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 2.5341e-04 - acc: 1.0000 - val_loss: 0.1368 - val_acc: 0.9762\n",
      "Epoch 686/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 2.5303e-04 - acc: 1.0000 - val_loss: 0.1369 - val_acc: 0.9762\n",
      "Epoch 687/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.5239e-04 - acc: 1.0000 - val_loss: 0.1368 - val_acc: 0.9761\n",
      "Epoch 688/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.5199e-04 - acc: 1.0000 - val_loss: 0.1367 - val_acc: 0.9759\n",
      "Epoch 689/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.5166e-04 - acc: 1.0000 - val_loss: 0.1372 - val_acc: 0.9761\n",
      "Epoch 690/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.5087e-04 - acc: 1.0000 - val_loss: 0.1370 - val_acc: 0.9760\n",
      "Epoch 691/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.5092e-04 - acc: 1.0000 - val_loss: 0.1371 - val_acc: 0.9761\n",
      "Epoch 692/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.4991e-04 - acc: 1.0000 - val_loss: 0.1369 - val_acc: 0.9757\n",
      "Epoch 693/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.4965e-04 - acc: 1.0000 - val_loss: 0.1373 - val_acc: 0.9763\n",
      "Epoch 694/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.4944e-04 - acc: 1.0000 - val_loss: 0.1370 - val_acc: 0.9760\n",
      "Epoch 695/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.4886e-04 - acc: 1.0000 - val_loss: 0.1370 - val_acc: 0.9760\n",
      "Epoch 696/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 2.4807e-04 - acc: 1.0000 - val_loss: 0.1371 - val_acc: 0.9759\n",
      "Epoch 697/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.4796e-04 - acc: 1.0000 - val_loss: 0.1370 - val_acc: 0.9762\n",
      "Epoch 698/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.4757e-04 - acc: 1.0000 - val_loss: 0.1372 - val_acc: 0.9760\n",
      "Epoch 699/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 2.4699e-04 - acc: 1.0000 - val_loss: 0.1372 - val_acc: 0.9761\n",
      "Epoch 700/1000\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 2.4655e-04 - acc: 1.0000 - val_loss: 0.1370 - val_acc: 0.9759\n",
      "Epoch 701/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 2.4618e-04 - acc: 1.0000 - val_loss: 0.1372 - val_acc: 0.9762\n",
      "Epoch 702/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.4546e-04 - acc: 1.0000 - val_loss: 0.1373 - val_acc: 0.9758\n",
      "Epoch 703/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 2.4521e-04 - acc: 1.0000 - val_loss: 0.1374 - val_acc: 0.9761\n",
      "Epoch 704/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 2.4488e-04 - acc: 1.0000 - val_loss: 0.1374 - val_acc: 0.9761\n",
      "Epoch 705/1000\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 2.4391e-04 - acc: 1.0000 - val_loss: 0.1377 - val_acc: 0.9760\n",
      "Epoch 706/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 2.4392e-04 - acc: 1.0000 - val_loss: 0.1375 - val_acc: 0.9761\n",
      "Epoch 707/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 2.4322e-04 - acc: 1.0000 - val_loss: 0.1374 - val_acc: 0.9758\n",
      "Epoch 708/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.4317e-04 - acc: 1.0000 - val_loss: 0.1374 - val_acc: 0.9761\n",
      "Epoch 709/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 2.4254e-04 - acc: 1.0000 - val_loss: 0.1374 - val_acc: 0.9760\n",
      "Epoch 710/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 2.4211e-04 - acc: 1.0000 - val_loss: 0.1374 - val_acc: 0.9761\n",
      "Epoch 711/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.4171e-04 - acc: 1.0000 - val_loss: 0.1376 - val_acc: 0.9759\n",
      "Epoch 712/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.4128e-04 - acc: 1.0000 - val_loss: 0.1377 - val_acc: 0.9762\n",
      "Epoch 713/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.4100e-04 - acc: 1.0000 - val_loss: 0.1375 - val_acc: 0.9760\n",
      "Epoch 714/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 2.4032e-04 - acc: 1.0000 - val_loss: 0.1376 - val_acc: 0.9758\n",
      "Epoch 715/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 2.3997e-04 - acc: 1.0000 - val_loss: 0.1377 - val_acc: 0.9761\n",
      "Epoch 716/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 2.3957e-04 - acc: 1.0000 - val_loss: 0.1377 - val_acc: 0.9762\n",
      "Epoch 717/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.3893e-04 - acc: 1.0000 - val_loss: 0.1375 - val_acc: 0.9757\n",
      "Epoch 718/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 2.3863e-04 - acc: 1.0000 - val_loss: 0.1376 - val_acc: 0.9761\n",
      "Epoch 719/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 2.3795e-04 - acc: 1.0000 - val_loss: 0.1375 - val_acc: 0.9761\n",
      "Epoch 720/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.3776e-04 - acc: 1.0000 - val_loss: 0.1378 - val_acc: 0.9761\n",
      "Epoch 721/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.3747e-04 - acc: 1.0000 - val_loss: 0.1378 - val_acc: 0.9762\n",
      "Epoch 722/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.3701e-04 - acc: 1.0000 - val_loss: 0.1376 - val_acc: 0.9760\n",
      "Epoch 723/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.3638e-04 - acc: 1.0000 - val_loss: 0.1376 - val_acc: 0.9759\n",
      "Epoch 724/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.3642e-04 - acc: 1.0000 - val_loss: 0.1377 - val_acc: 0.9761\n",
      "Epoch 725/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.3570e-04 - acc: 1.0000 - val_loss: 0.1377 - val_acc: 0.9761\n",
      "Epoch 726/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.3493e-04 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9760\n",
      "Epoch 727/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.3492e-04 - acc: 1.0000 - val_loss: 0.1378 - val_acc: 0.9759\n",
      "Epoch 728/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.3474e-04 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9763\n",
      "Epoch 729/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.3400e-04 - acc: 1.0000 - val_loss: 0.1377 - val_acc: 0.9760\n",
      "Epoch 730/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.3397e-04 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9760\n",
      "Epoch 731/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.3318e-04 - acc: 1.0000 - val_loss: 0.1377 - val_acc: 0.9762\n",
      "Epoch 732/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.3298e-04 - acc: 1.0000 - val_loss: 0.1378 - val_acc: 0.9762\n",
      "Epoch 733/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.3238e-04 - acc: 1.0000 - val_loss: 0.1380 - val_acc: 0.9762\n",
      "Epoch 734/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.3218e-04 - acc: 1.0000 - val_loss: 0.1380 - val_acc: 0.9759\n",
      "Epoch 735/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.3184e-04 - acc: 1.0000 - val_loss: 0.1380 - val_acc: 0.9762\n",
      "Epoch 736/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.3130e-04 - acc: 1.0000 - val_loss: 0.1381 - val_acc: 0.9763\n",
      "Epoch 737/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.3101e-04 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9761\n",
      "Epoch 738/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.3060e-04 - acc: 1.0000 - val_loss: 0.1382 - val_acc: 0.9763\n",
      "Epoch 739/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.3024e-04 - acc: 1.0000 - val_loss: 0.1382 - val_acc: 0.9762\n",
      "Epoch 740/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 2.2974e-04 - acc: 1.0000 - val_loss: 0.1380 - val_acc: 0.9761\n",
      "Epoch 741/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 2.2943e-04 - acc: 1.0000 - val_loss: 0.1381 - val_acc: 0.9760\n",
      "Epoch 742/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.2894e-04 - acc: 1.0000 - val_loss: 0.1382 - val_acc: 0.9759\n",
      "Epoch 743/1000\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 2.2844e-04 - acc: 1.0000 - val_loss: 0.1383 - val_acc: 0.9763\n",
      "Epoch 744/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2824e-04 - acc: 1.0000 - val_loss: 0.1381 - val_acc: 0.9761\n",
      "Epoch 745/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.2770e-04 - acc: 1.0000 - val_loss: 0.1380 - val_acc: 0.9762\n",
      "Epoch 746/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2740e-04 - acc: 1.0000 - val_loss: 0.1382 - val_acc: 0.9758\n",
      "Epoch 747/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.2703e-04 - acc: 1.0000 - val_loss: 0.1384 - val_acc: 0.9761\n",
      "Epoch 748/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.2658e-04 - acc: 1.0000 - val_loss: 0.1383 - val_acc: 0.9761\n",
      "Epoch 749/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2619e-04 - acc: 1.0000 - val_loss: 0.1384 - val_acc: 0.9760\n",
      "Epoch 750/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2547e-04 - acc: 1.0000 - val_loss: 0.1383 - val_acc: 0.9761\n",
      "Epoch 751/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2559e-04 - acc: 1.0000 - val_loss: 0.1382 - val_acc: 0.9760\n",
      "Epoch 752/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.2502e-04 - acc: 1.0000 - val_loss: 0.1384 - val_acc: 0.9762\n",
      "Epoch 753/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2477e-04 - acc: 1.0000 - val_loss: 0.1384 - val_acc: 0.9760\n",
      "Epoch 754/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2438e-04 - acc: 1.0000 - val_loss: 0.1384 - val_acc: 0.9763\n",
      "Epoch 755/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2389e-04 - acc: 1.0000 - val_loss: 0.1384 - val_acc: 0.9761\n",
      "Epoch 756/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2351e-04 - acc: 1.0000 - val_loss: 0.1384 - val_acc: 0.9761\n",
      "Epoch 757/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.2321e-04 - acc: 1.0000 - val_loss: 0.1384 - val_acc: 0.9762\n",
      "Epoch 758/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2293e-04 - acc: 1.0000 - val_loss: 0.1385 - val_acc: 0.9761\n",
      "Epoch 759/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2247e-04 - acc: 1.0000 - val_loss: 0.1385 - val_acc: 0.9760\n",
      "Epoch 760/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2218e-04 - acc: 1.0000 - val_loss: 0.1384 - val_acc: 0.9762\n",
      "Epoch 761/1000\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 2.2177e-04 - acc: 1.0000 - val_loss: 0.1385 - val_acc: 0.9761\n",
      "Epoch 762/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 2.2121e-04 - acc: 1.0000 - val_loss: 0.1385 - val_acc: 0.9759\n",
      "Epoch 763/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2105e-04 - acc: 1.0000 - val_loss: 0.1386 - val_acc: 0.9761\n",
      "Epoch 764/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.2060e-04 - acc: 1.0000 - val_loss: 0.1387 - val_acc: 0.9760\n",
      "Epoch 765/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.2026e-04 - acc: 1.0000 - val_loss: 0.1387 - val_acc: 0.9761\n",
      "Epoch 766/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.1972e-04 - acc: 1.0000 - val_loss: 0.1387 - val_acc: 0.9763\n",
      "Epoch 767/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.1957e-04 - acc: 1.0000 - val_loss: 0.1387 - val_acc: 0.9762\n",
      "Epoch 768/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.1925e-04 - acc: 1.0000 - val_loss: 0.1387 - val_acc: 0.9762\n",
      "Epoch 769/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.1879e-04 - acc: 1.0000 - val_loss: 0.1386 - val_acc: 0.9760\n",
      "Epoch 770/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.1846e-04 - acc: 1.0000 - val_loss: 0.1388 - val_acc: 0.9760\n",
      "Epoch 771/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.1811e-04 - acc: 1.0000 - val_loss: 0.1388 - val_acc: 0.9762\n",
      "Epoch 772/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.1765e-04 - acc: 1.0000 - val_loss: 0.1387 - val_acc: 0.9759\n",
      "Epoch 773/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.1744e-04 - acc: 1.0000 - val_loss: 0.1389 - val_acc: 0.9760\n",
      "Epoch 774/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 2.1696e-04 - acc: 1.0000 - val_loss: 0.1387 - val_acc: 0.9759\n",
      "Epoch 775/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.1688e-04 - acc: 1.0000 - val_loss: 0.1389 - val_acc: 0.9761\n",
      "Epoch 776/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.1645e-04 - acc: 1.0000 - val_loss: 0.1388 - val_acc: 0.9761\n",
      "Epoch 777/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.1593e-04 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9760\n",
      "Epoch 778/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.1556e-04 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9762\n",
      "Epoch 779/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.1521e-04 - acc: 1.0000 - val_loss: 0.1389 - val_acc: 0.9762\n",
      "Epoch 780/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.1503e-04 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9761\n",
      "Epoch 781/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.1452e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9762\n",
      "Epoch 782/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.1422e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9760\n",
      "Epoch 783/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.1400e-04 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9761\n",
      "Epoch 784/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.1352e-04 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9760\n",
      "Epoch 785/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.1326e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9761\n",
      "Epoch 786/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.1284e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9760\n",
      "Epoch 787/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.1227e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9761\n",
      "Epoch 788/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.1225e-04 - acc: 1.0000 - val_loss: 0.1392 - val_acc: 0.9760\n",
      "Epoch 789/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.1183e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9761\n",
      "Epoch 790/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.1142e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9762\n",
      "Epoch 791/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.1112e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9762\n",
      "Epoch 792/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.1076e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9761\n",
      "Epoch 793/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.1046e-04 - acc: 1.0000 - val_loss: 0.1392 - val_acc: 0.9762\n",
      "Epoch 794/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.1003e-04 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.9762\n",
      "Epoch 795/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.0977e-04 - acc: 1.0000 - val_loss: 0.1393 - val_acc: 0.9762\n",
      "Epoch 796/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.0944e-04 - acc: 1.0000 - val_loss: 0.1393 - val_acc: 0.9761\n",
      "Epoch 797/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0903e-04 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.9762\n",
      "Epoch 798/1000\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 2.0863e-04 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.9759\n",
      "Epoch 799/1000\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 2.0850e-04 - acc: 1.0000 - val_loss: 0.1393 - val_acc: 0.9762\n",
      "Epoch 800/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0817e-04 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.9761\n",
      "Epoch 801/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.0787e-04 - acc: 1.0000 - val_loss: 0.1395 - val_acc: 0.9761\n",
      "Epoch 802/1000\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 2.0738e-04 - acc: 1.0000 - val_loss: 0.1396 - val_acc: 0.9762\n",
      "Epoch 803/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0713e-04 - acc: 1.0000 - val_loss: 0.1396 - val_acc: 0.9760\n",
      "Epoch 804/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0686e-04 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.9762\n",
      "Epoch 805/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0641e-04 - acc: 1.0000 - val_loss: 0.1396 - val_acc: 0.9763\n",
      "Epoch 806/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.0628e-04 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.9763\n",
      "Epoch 807/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0582e-04 - acc: 1.0000 - val_loss: 0.1396 - val_acc: 0.9762\n",
      "Epoch 808/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0570e-04 - acc: 1.0000 - val_loss: 0.1395 - val_acc: 0.9761\n",
      "Epoch 809/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0522e-04 - acc: 1.0000 - val_loss: 0.1396 - val_acc: 0.9760\n",
      "Epoch 810/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.0504e-04 - acc: 1.0000 - val_loss: 0.1396 - val_acc: 0.9760\n",
      "Epoch 811/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.0451e-04 - acc: 1.0000 - val_loss: 0.1395 - val_acc: 0.9761\n",
      "Epoch 812/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0426e-04 - acc: 1.0000 - val_loss: 0.1395 - val_acc: 0.9762\n",
      "Epoch 813/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0383e-04 - acc: 1.0000 - val_loss: 0.1396 - val_acc: 0.9761\n",
      "Epoch 814/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0338e-04 - acc: 1.0000 - val_loss: 0.1399 - val_acc: 0.9761\n",
      "Epoch 815/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.0332e-04 - acc: 1.0000 - val_loss: 0.1398 - val_acc: 0.9762\n",
      "Epoch 816/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.0300e-04 - acc: 1.0000 - val_loss: 0.1396 - val_acc: 0.9762\n",
      "Epoch 817/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.0271e-04 - acc: 1.0000 - val_loss: 0.1399 - val_acc: 0.9762\n",
      "Epoch 818/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0237e-04 - acc: 1.0000 - val_loss: 0.1397 - val_acc: 0.9762\n",
      "Epoch 819/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0214e-04 - acc: 1.0000 - val_loss: 0.1397 - val_acc: 0.9762\n",
      "Epoch 820/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.0173e-04 - acc: 1.0000 - val_loss: 0.1398 - val_acc: 0.9761\n",
      "Epoch 821/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0130e-04 - acc: 1.0000 - val_loss: 0.1399 - val_acc: 0.9763\n",
      "Epoch 822/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0110e-04 - acc: 1.0000 - val_loss: 0.1398 - val_acc: 0.9762\n",
      "Epoch 823/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 2.0089e-04 - acc: 1.0000 - val_loss: 0.1400 - val_acc: 0.9763\n",
      "Epoch 824/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.0057e-04 - acc: 1.0000 - val_loss: 0.1398 - val_acc: 0.9760\n",
      "Epoch 825/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.0039e-04 - acc: 1.0000 - val_loss: 0.1399 - val_acc: 0.9761\n",
      "Epoch 826/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.9999e-04 - acc: 1.0000 - val_loss: 0.1400 - val_acc: 0.9761\n",
      "Epoch 827/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 1.9933e-04 - acc: 1.0000 - val_loss: 0.1400 - val_acc: 0.9760\n",
      "Epoch 828/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 1.9941e-04 - acc: 1.0000 - val_loss: 0.1401 - val_acc: 0.9762\n",
      "Epoch 829/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.9892e-04 - acc: 1.0000 - val_loss: 0.1398 - val_acc: 0.9760\n",
      "Epoch 830/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.9870e-04 - acc: 1.0000 - val_loss: 0.1400 - val_acc: 0.9760\n",
      "Epoch 831/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9847e-04 - acc: 1.0000 - val_loss: 0.1399 - val_acc: 0.9760\n",
      "Epoch 832/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9822e-04 - acc: 1.0000 - val_loss: 0.1400 - val_acc: 0.9760\n",
      "Epoch 833/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9782e-04 - acc: 1.0000 - val_loss: 0.1401 - val_acc: 0.9761\n",
      "Epoch 834/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9741e-04 - acc: 1.0000 - val_loss: 0.1401 - val_acc: 0.9760\n",
      "Epoch 835/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.9729e-04 - acc: 1.0000 - val_loss: 0.1400 - val_acc: 0.9761\n",
      "Epoch 836/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.9698e-04 - acc: 1.0000 - val_loss: 0.1401 - val_acc: 0.9761\n",
      "Epoch 837/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9664e-04 - acc: 1.0000 - val_loss: 0.1400 - val_acc: 0.9761\n",
      "Epoch 838/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9632e-04 - acc: 1.0000 - val_loss: 0.1402 - val_acc: 0.9762\n",
      "Epoch 839/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9599e-04 - acc: 1.0000 - val_loss: 0.1402 - val_acc: 0.9760\n",
      "Epoch 840/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.9566e-04 - acc: 1.0000 - val_loss: 0.1400 - val_acc: 0.9761\n",
      "Epoch 841/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9542e-04 - acc: 1.0000 - val_loss: 0.1403 - val_acc: 0.9762\n",
      "Epoch 842/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9505e-04 - acc: 1.0000 - val_loss: 0.1402 - val_acc: 0.9760\n",
      "Epoch 843/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9489e-04 - acc: 1.0000 - val_loss: 0.1402 - val_acc: 0.9763\n",
      "Epoch 844/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.9448e-04 - acc: 1.0000 - val_loss: 0.1401 - val_acc: 0.9760\n",
      "Epoch 845/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.9422e-04 - acc: 1.0000 - val_loss: 0.1403 - val_acc: 0.9760\n",
      "Epoch 846/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9399e-04 - acc: 1.0000 - val_loss: 0.1404 - val_acc: 0.9759\n",
      "Epoch 847/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9376e-04 - acc: 1.0000 - val_loss: 0.1403 - val_acc: 0.9762\n",
      "Epoch 848/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 101us/step - loss: 1.9336e-04 - acc: 1.0000 - val_loss: 0.1404 - val_acc: 0.9760\n",
      "Epoch 849/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9313e-04 - acc: 1.0000 - val_loss: 0.1402 - val_acc: 0.9759\n",
      "Epoch 850/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.9282e-04 - acc: 1.0000 - val_loss: 0.1403 - val_acc: 0.9761\n",
      "Epoch 851/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9256e-04 - acc: 1.0000 - val_loss: 0.1404 - val_acc: 0.9761\n",
      "Epoch 852/1000\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 1.9242e-04 - acc: 1.0000 - val_loss: 0.1404 - val_acc: 0.9760\n",
      "Epoch 853/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9185e-04 - acc: 1.0000 - val_loss: 0.1406 - val_acc: 0.9762\n",
      "Epoch 854/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.9171e-04 - acc: 1.0000 - val_loss: 0.1404 - val_acc: 0.9761\n",
      "Epoch 855/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9153e-04 - acc: 1.0000 - val_loss: 0.1405 - val_acc: 0.9761\n",
      "Epoch 856/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9120e-04 - acc: 1.0000 - val_loss: 0.1405 - val_acc: 0.9762\n",
      "Epoch 857/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9090e-04 - acc: 1.0000 - val_loss: 0.1405 - val_acc: 0.9760\n",
      "Epoch 858/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.9054e-04 - acc: 1.0000 - val_loss: 0.1407 - val_acc: 0.9761\n",
      "Epoch 859/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.9021e-04 - acc: 1.0000 - val_loss: 0.1406 - val_acc: 0.9762\n",
      "Epoch 860/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.9000e-04 - acc: 1.0000 - val_loss: 0.1406 - val_acc: 0.9761\n",
      "Epoch 861/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.8968e-04 - acc: 1.0000 - val_loss: 0.1405 - val_acc: 0.9760\n",
      "Epoch 862/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.8949e-04 - acc: 1.0000 - val_loss: 0.1406 - val_acc: 0.9761\n",
      "Epoch 863/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.8900e-04 - acc: 1.0000 - val_loss: 0.1406 - val_acc: 0.9760\n",
      "Epoch 864/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.8904e-04 - acc: 1.0000 - val_loss: 0.1406 - val_acc: 0.9762\n",
      "Epoch 865/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8873e-04 - acc: 1.0000 - val_loss: 0.1406 - val_acc: 0.9762\n",
      "Epoch 866/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.8842e-04 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 0.9762\n",
      "Epoch 867/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.8814e-04 - acc: 1.0000 - val_loss: 0.1407 - val_acc: 0.9761\n",
      "Epoch 868/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.8786e-04 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 0.9761\n",
      "Epoch 869/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8751e-04 - acc: 1.0000 - val_loss: 0.1409 - val_acc: 0.9762\n",
      "Epoch 870/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.8718e-04 - acc: 1.0000 - val_loss: 0.1409 - val_acc: 0.9762\n",
      "Epoch 871/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.8710e-04 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 0.9761\n",
      "Epoch 872/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.8670e-04 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 0.9759\n",
      "Epoch 873/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.8655e-04 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 0.9760\n",
      "Epoch 874/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.8615e-04 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 0.9762\n",
      "Epoch 875/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.8601e-04 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 0.9761\n",
      "Epoch 876/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.8572e-04 - acc: 1.0000 - val_loss: 0.1410 - val_acc: 0.9762\n",
      "Epoch 877/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.8548e-04 - acc: 1.0000 - val_loss: 0.1410 - val_acc: 0.9762\n",
      "Epoch 878/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8509e-04 - acc: 1.0000 - val_loss: 0.1410 - val_acc: 0.9763\n",
      "Epoch 879/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.8490e-04 - acc: 1.0000 - val_loss: 0.1409 - val_acc: 0.9762\n",
      "Epoch 880/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 1.8453e-04 - acc: 1.0000 - val_loss: 0.1411 - val_acc: 0.9761\n",
      "Epoch 881/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8438e-04 - acc: 1.0000 - val_loss: 0.1409 - val_acc: 0.9762\n",
      "Epoch 882/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8415e-04 - acc: 1.0000 - val_loss: 0.1410 - val_acc: 0.9760\n",
      "Epoch 883/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8390e-04 - acc: 1.0000 - val_loss: 0.1410 - val_acc: 0.9761\n",
      "Epoch 884/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.8362e-04 - acc: 1.0000 - val_loss: 0.1410 - val_acc: 0.9762\n",
      "Epoch 885/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8343e-04 - acc: 1.0000 - val_loss: 0.1411 - val_acc: 0.9761\n",
      "Epoch 886/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8305e-04 - acc: 1.0000 - val_loss: 0.1410 - val_acc: 0.9760\n",
      "Epoch 887/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.8280e-04 - acc: 1.0000 - val_loss: 0.1411 - val_acc: 0.9761\n",
      "Epoch 888/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8250e-04 - acc: 1.0000 - val_loss: 0.1410 - val_acc: 0.9761\n",
      "Epoch 889/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.8220e-04 - acc: 1.0000 - val_loss: 0.1412 - val_acc: 0.9761\n",
      "Epoch 890/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.8205e-04 - acc: 1.0000 - val_loss: 0.1411 - val_acc: 0.9760\n",
      "Epoch 891/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8186e-04 - acc: 1.0000 - val_loss: 0.1412 - val_acc: 0.9762\n",
      "Epoch 892/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8149e-04 - acc: 1.0000 - val_loss: 0.1412 - val_acc: 0.9761\n",
      "Epoch 893/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.8121e-04 - acc: 1.0000 - val_loss: 0.1412 - val_acc: 0.9760\n",
      "Epoch 894/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.8115e-04 - acc: 1.0000 - val_loss: 0.1412 - val_acc: 0.9761\n",
      "Epoch 895/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8081e-04 - acc: 1.0000 - val_loss: 0.1412 - val_acc: 0.9761\n",
      "Epoch 896/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8050e-04 - acc: 1.0000 - val_loss: 0.1414 - val_acc: 0.9761\n",
      "Epoch 897/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.8021e-04 - acc: 1.0000 - val_loss: 0.1412 - val_acc: 0.9761\n",
      "Epoch 898/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.7998e-04 - acc: 1.0000 - val_loss: 0.1412 - val_acc: 0.9761\n",
      "Epoch 899/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.7980e-04 - acc: 1.0000 - val_loss: 0.1412 - val_acc: 0.9762\n",
      "Epoch 900/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.7946e-04 - acc: 1.0000 - val_loss: 0.1414 - val_acc: 0.9763\n",
      "Epoch 901/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.7930e-04 - acc: 1.0000 - val_loss: 0.1415 - val_acc: 0.9762\n",
      "Epoch 902/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.7898e-04 - acc: 1.0000 - val_loss: 0.1414 - val_acc: 0.9761\n",
      "Epoch 903/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 1.7864e-04 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9761\n",
      "Epoch 904/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7865e-04 - acc: 1.0000 - val_loss: 0.1414 - val_acc: 0.9761\n",
      "Epoch 905/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7825e-04 - acc: 1.0000 - val_loss: 0.1415 - val_acc: 0.9760\n",
      "Epoch 906/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7805e-04 - acc: 1.0000 - val_loss: 0.1414 - val_acc: 0.9760\n",
      "Epoch 907/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.7767e-04 - acc: 1.0000 - val_loss: 0.1415 - val_acc: 0.9762\n",
      "Epoch 908/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.7754e-04 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9761\n",
      "Epoch 909/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.7727e-04 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9762\n",
      "Epoch 910/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7707e-04 - acc: 1.0000 - val_loss: 0.1414 - val_acc: 0.9762\n",
      "Epoch 911/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.7675e-04 - acc: 1.0000 - val_loss: 0.1417 - val_acc: 0.9761\n",
      "Epoch 912/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7652e-04 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9761\n",
      "Epoch 913/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.7624e-04 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9760\n",
      "Epoch 914/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.7615e-04 - acc: 1.0000 - val_loss: 0.1417 - val_acc: 0.9763\n",
      "Epoch 915/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.7600e-04 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9762\n",
      "Epoch 916/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 1.7563e-04 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9762\n",
      "Epoch 917/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7529e-04 - acc: 1.0000 - val_loss: 0.1415 - val_acc: 0.9763\n",
      "Epoch 918/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.7507e-04 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9761\n",
      "Epoch 919/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7490e-04 - acc: 1.0000 - val_loss: 0.1417 - val_acc: 0.9762\n",
      "Epoch 920/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7470e-04 - acc: 1.0000 - val_loss: 0.1417 - val_acc: 0.9760\n",
      "Epoch 921/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 1.7438e-04 - acc: 1.0000 - val_loss: 0.1418 - val_acc: 0.9762\n",
      "Epoch 922/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 1.7424e-04 - acc: 1.0000 - val_loss: 0.1417 - val_acc: 0.9762\n",
      "Epoch 923/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.7397e-04 - acc: 1.0000 - val_loss: 0.1418 - val_acc: 0.9761\n",
      "Epoch 924/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7379e-04 - acc: 1.0000 - val_loss: 0.1418 - val_acc: 0.9761\n",
      "Epoch 925/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7352e-04 - acc: 1.0000 - val_loss: 0.1418 - val_acc: 0.9760\n",
      "Epoch 926/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7326e-04 - acc: 1.0000 - val_loss: 0.1418 - val_acc: 0.9761\n",
      "Epoch 927/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.7297e-04 - acc: 1.0000 - val_loss: 0.1417 - val_acc: 0.9762\n",
      "Epoch 928/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7273e-04 - acc: 1.0000 - val_loss: 0.1419 - val_acc: 0.9763\n",
      "Epoch 929/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7258e-04 - acc: 1.0000 - val_loss: 0.1418 - val_acc: 0.9761\n",
      "Epoch 930/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.7232e-04 - acc: 1.0000 - val_loss: 0.1418 - val_acc: 0.9762\n",
      "Epoch 931/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.7214e-04 - acc: 1.0000 - val_loss: 0.1419 - val_acc: 0.9761\n",
      "Epoch 932/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.7183e-04 - acc: 1.0000 - val_loss: 0.1420 - val_acc: 0.9762\n",
      "Epoch 933/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.7158e-04 - acc: 1.0000 - val_loss: 0.1419 - val_acc: 0.9761\n",
      "Epoch 934/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7147e-04 - acc: 1.0000 - val_loss: 0.1419 - val_acc: 0.9761\n",
      "Epoch 935/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7107e-04 - acc: 1.0000 - val_loss: 0.1420 - val_acc: 0.9761\n",
      "Epoch 936/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7096e-04 - acc: 1.0000 - val_loss: 0.1421 - val_acc: 0.9761\n",
      "Epoch 937/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.7067e-04 - acc: 1.0000 - val_loss: 0.1420 - val_acc: 0.9761\n",
      "Epoch 938/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.7042e-04 - acc: 1.0000 - val_loss: 0.1420 - val_acc: 0.9761\n",
      "Epoch 939/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.7031e-04 - acc: 1.0000 - val_loss: 0.1421 - val_acc: 0.9762\n",
      "Epoch 940/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.6995e-04 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9762\n",
      "Epoch 941/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6986e-04 - acc: 1.0000 - val_loss: 0.1421 - val_acc: 0.9761\n",
      "Epoch 942/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.6958e-04 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9760\n",
      "Epoch 943/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.6934e-04 - acc: 1.0000 - val_loss: 0.1420 - val_acc: 0.9760\n",
      "Epoch 944/1000\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 1.6913e-04 - acc: 1.0000 - val_loss: 0.1420 - val_acc: 0.9760\n",
      "Epoch 945/1000\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 1.6888e-04 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9760\n",
      "Epoch 946/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 1.6857e-04 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9763\n",
      "Epoch 947/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.6847e-04 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9760\n",
      "Epoch 948/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.6830e-04 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9761\n",
      "Epoch 949/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.6806e-04 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9760\n",
      "Epoch 950/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 1.6781e-04 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9761\n",
      "Epoch 951/1000\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 1.6762e-04 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9762\n",
      "Epoch 952/1000\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 1.6743e-04 - acc: 1.0000 - val_loss: 0.1423 - val_acc: 0.9761\n",
      "Epoch 953/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 1.6701e-04 - acc: 1.0000 - val_loss: 0.1423 - val_acc: 0.9763\n",
      "Epoch 954/1000\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 1.6693e-04 - acc: 1.0000 - val_loss: 0.1424 - val_acc: 0.9762\n",
      "Epoch 955/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 1.6658e-04 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9760\n",
      "Epoch 956/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.6660e-04 - acc: 1.0000 - val_loss: 0.1423 - val_acc: 0.9761\n",
      "Epoch 957/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.6628e-04 - acc: 1.0000 - val_loss: 0.1423 - val_acc: 0.9761\n",
      "Epoch 958/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 1.6609e-04 - acc: 1.0000 - val_loss: 0.1423 - val_acc: 0.9761\n",
      "Epoch 959/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 1.6583e-04 - acc: 1.0000 - val_loss: 0.1423 - val_acc: 0.9761\n",
      "Epoch 960/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 7s 118us/step - loss: 1.6559e-04 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9762\n",
      "Epoch 961/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.6551e-04 - acc: 1.0000 - val_loss: 0.1424 - val_acc: 0.9762\n",
      "Epoch 962/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6522e-04 - acc: 1.0000 - val_loss: 0.1424 - val_acc: 0.9761\n",
      "Epoch 963/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6497e-04 - acc: 1.0000 - val_loss: 0.1424 - val_acc: 0.9763\n",
      "Epoch 964/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 1.6479e-04 - acc: 1.0000 - val_loss: 0.1424 - val_acc: 0.9760\n",
      "Epoch 965/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 1.6458e-04 - acc: 1.0000 - val_loss: 0.1425 - val_acc: 0.9762\n",
      "Epoch 966/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6430e-04 - acc: 1.0000 - val_loss: 0.1424 - val_acc: 0.9760\n",
      "Epoch 967/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6419e-04 - acc: 1.0000 - val_loss: 0.1425 - val_acc: 0.9761\n",
      "Epoch 968/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6388e-04 - acc: 1.0000 - val_loss: 0.1425 - val_acc: 0.9761\n",
      "Epoch 969/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.6372e-04 - acc: 1.0000 - val_loss: 0.1425 - val_acc: 0.9763\n",
      "Epoch 970/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.6345e-04 - acc: 1.0000 - val_loss: 0.1426 - val_acc: 0.9761\n",
      "Epoch 971/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6332e-04 - acc: 1.0000 - val_loss: 0.1425 - val_acc: 0.9762\n",
      "Epoch 972/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6314e-04 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9762\n",
      "Epoch 973/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6289e-04 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9762\n",
      "Epoch 974/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6267e-04 - acc: 1.0000 - val_loss: 0.1426 - val_acc: 0.9761\n",
      "Epoch 975/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.6235e-04 - acc: 1.0000 - val_loss: 0.1426 - val_acc: 0.9760\n",
      "Epoch 976/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6216e-04 - acc: 1.0000 - val_loss: 0.1426 - val_acc: 0.9763\n",
      "Epoch 977/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6202e-04 - acc: 1.0000 - val_loss: 0.1426 - val_acc: 0.9762\n",
      "Epoch 978/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.6184e-04 - acc: 1.0000 - val_loss: 0.1428 - val_acc: 0.9762\n",
      "Epoch 979/1000\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 1.6163e-04 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9761\n",
      "Epoch 980/1000\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 1.6118e-04 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9760\n",
      "Epoch 981/1000\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 1.6116e-04 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9761\n",
      "Epoch 982/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6101e-04 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9763\n",
      "Epoch 983/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6083e-04 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9762\n",
      "Epoch 984/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.6051e-04 - acc: 1.0000 - val_loss: 0.1428 - val_acc: 0.9761\n",
      "Epoch 985/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6041e-04 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 0.9762\n",
      "Epoch 986/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6015e-04 - acc: 1.0000 - val_loss: 0.1430 - val_acc: 0.9762\n",
      "Epoch 987/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.6004e-04 - acc: 1.0000 - val_loss: 0.1428 - val_acc: 0.9761\n",
      "Epoch 988/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.5981e-04 - acc: 1.0000 - val_loss: 0.1428 - val_acc: 0.9761\n",
      "Epoch 989/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.5959e-04 - acc: 1.0000 - val_loss: 0.1428 - val_acc: 0.9761\n",
      "Epoch 990/1000\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.5940e-04 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 0.9760\n",
      "Epoch 991/1000\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 1.5916e-04 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 0.9762\n",
      "Epoch 992/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.5901e-04 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 0.9763\n",
      "Epoch 993/1000\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 1.5871e-04 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9764\n",
      "Epoch 994/1000\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 1.5857e-04 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 0.9762\n",
      "Epoch 995/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.5839e-04 - acc: 1.0000 - val_loss: 0.1431 - val_acc: 0.9762\n",
      "Epoch 996/1000\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 1.5813e-04 - acc: 1.0000 - val_loss: 0.1431 - val_acc: 0.9762\n",
      "Epoch 997/1000\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 1.5798e-04 - acc: 1.0000 - val_loss: 0.1430 - val_acc: 0.9764\n",
      "Epoch 998/1000\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 1.5776e-04 - acc: 1.0000 - val_loss: 0.1430 - val_acc: 0.9762\n",
      "Epoch 999/1000\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 1.5753e-04 - acc: 1.0000 - val_loss: 0.1431 - val_acc: 0.9760\n",
      "Epoch 1000/1000\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 1.5733e-04 - acc: 1.0000 - val_loss: 0.1430 - val_acc: 0.9760\n",
      "[0.23558112449866409, 0.19318429154537928, 0.16403139521189344, 0.14337146353607144, 0.12827044936533397, 0.11591957358531847, 0.10632447865324017, 0.09831601986162908, 0.09175069223654767, 0.08566478233441982, 0.08058039026315479, 0.07575603926632903, 0.07181059007636699, 0.06783644187559548, 0.0642479742057088, 0.06108642817180225, 0.058401757641525665, 0.05525357716735258, 0.05301588849856368, 0.05069114219568898, 0.048003673634727115, 0.04616986174459695, 0.04438435197648748, 0.04270767893121835, 0.0408122324954129, 0.03938657147121194, 0.03757316363572196, 0.03641247344151877, 0.0348433155047951, 0.03336392665030568, 0.03217283135719542, 0.031046530267640263, 0.02989286962240658, 0.028840601675982423, 0.027671288123045694, 0.02678508405366726, 0.025762289179458397, 0.02492614777764538, 0.024003301175309237, 0.02306224461728349, 0.02230721677674107, 0.02140849046499928, 0.020835592435928144, 0.020031255195500915, 0.019606458057619725, 0.018555248695185128, 0.018060136072634427, 0.01749727019821239, 0.016977782123850982, 0.016371439126093415, 0.015756127600270398, 0.01527097300429629, 0.014890115122110937, 0.014268195337156802, 0.013870737620472862, 0.013441400427629636, 0.013007817669869382, 0.012605278667194702, 0.012105316292810054, 0.011752788843904283, 0.01138453721170553, 0.011285532454272926, 0.010795628177080024, 0.010519855148752867, 0.010221599228593694, 0.0099282644530392, 0.009583557369250116, 0.009268401346191505, 0.009028663578688945, 0.0088429530875084, 0.008604478056021757, 0.008402960436392543, 0.008113372008202646, 0.007927219407107885, 0.0077467225889696276, 0.007609723332941163, 0.007375228589944536, 0.007137117332035719, 0.006970775688227017, 0.006806730477427972, 0.006590695687627686, 0.006504160219338113, 0.006370835298362436, 0.006140802043936522, 0.006078973799840299, 0.00592724412458504, 0.005740425654056821, 0.0057003613196940535, 0.005490546819772632, 0.005421951246580316, 0.0053398723932541635, 0.005213760077658194, 0.005091708393949745, 0.004975674338880699, 0.004876866781042906, 0.004791058158177017, 0.004710536029405385, 0.004644034338902155, 0.004520487086007269, 0.004438553067468329, 0.004368690534317058, 0.004253820129895966, 0.0042246268531843136, 0.004116763226387718, 0.004053289079640813, 0.00400301056424784, 0.003896301798380501, 0.00384478406123061, 0.0037579847877445803, 0.0037244297740049036, 0.0036531349515694297, 0.003607457940969302, 0.003552734029476883, 0.0034650775919206466, 0.0034290984566222324, 0.003398034809255049, 0.003342045361105117, 0.0032789563065304082, 0.003218952459206491, 0.0031659412451796667, 0.003158799339305652, 0.0030660693529326864, 0.003036974687834655, 0.003004092146260144, 0.0029669421055131054, 0.0029082867430653466, 0.0028562775975065715, 0.0028477294765928084, 0.002823003261724935, 0.002763921135614879, 0.002721395819658459, 0.0027078880891949664, 0.0026587013125766723, 0.002644214897759973, 0.002597387753805613, 0.0025657664743326267, 0.00253058715212272, 0.0024921176145119924, 0.0024769845670026764, 0.002443264368071662, 0.002402496615309616, 0.002377056035932033, 0.002357882323215996, 0.002323278491219064, 0.0023010825859791522, 0.002275931627348863, 0.0022492165851098252, 0.002219630546498569, 0.0021947396865784796, 0.002182685302310027, 0.0021550228133729683, 0.002123331269025397, 0.0021011687838229302, 0.0020846962519313643, 0.002071310980133321, 0.0020336067511789934, 0.0020246115059395844, 0.0019854693661559464, 0.0019790082244697136, 0.001959030790279274, 0.001930119543996696, 0.001919012114760489, 0.0018961143378762343, 0.00188831216691131, 0.0018596474610178527, 0.0018532720894573274, 0.0018304872006887104, 0.0018091009239816008, 0.0017986574952320495, 0.0017680445071257722, 0.0017578360745658537, 0.0017475398783126153, 0.001731804458459429, 0.0017119247131331884, 0.0016951180778504427, 0.0016887780180180863, 0.0016662700382408411, 0.0016530221565014807, 0.0016336834212285277, 0.0016178402064105958, 0.0016088971689302222, 0.0015993959004323487, 0.001578431247864387, 0.0015675664058034968, 0.001554274839875641, 0.0015399597143971324, 0.0015295827347868898, 0.001521660334066188, 0.0015041721883220422, 0.001493812209961547, 0.0014787686650091132, 0.0014683286387937003, 0.0014592942762421425, 0.0014496397764377964, 0.0014349934969709016, 0.0014205854794803515, 0.0014118284752862446, 0.0014043444870010546, 0.0013895755661017025, 0.0013799567233599036, 0.0013649219016861594, 0.0013607104151076139, 0.0013478482495302918, 0.001338207922591316, 0.0013308607139904728, 0.0013158105584400938, 0.0013146495191838643, 0.001300609928351368, 0.0012878852044016847, 0.0012811353565496592, 0.0012730382514652447, 0.0012640833780875908, 0.0012585916568935882, 0.001245432218345208, 0.001236521979426494, 0.001227635227445648, 0.0012196355021161385, 0.0012131319215577866, 0.0012023591458537103, 0.0011978126707440542, 0.0011877556049530184, 0.0011779689625463709, 0.0011730920869861118, 0.0011638647426054144, 0.0011586654046719905, 0.001146666032467728, 0.0011414598877446784, 0.0011350387584427514, 0.0011256767016373389, 0.001119599863460311, 0.001111918586349186, 0.0011047693965696226, 0.001095281817876251, 0.0010940202872951328, 0.001083340841375725, 0.0010766759220650097, 0.0010697706317608607, 0.0010660719762500624, 0.0010548515160172538, 0.001052481102124015, 0.0010423453837350156, 0.0010355350802416083, 0.0010316457813136235, 0.0010278062475554109, 0.001019863998567523, 0.0010131036426342325, 0.0010089050882307736, 0.0010004375507057476, 0.0009948157996354065, 0.0009844691115539277, 0.0009857478303341054, 0.0009799703929576657, 0.0009741703043814406, 0.0009668504990724548, 0.000963281993288516, 0.0009572142237611132, 0.0009497170233046551, 0.0009466738366139324, 0.00094207692566156, 0.0009325317952771191, 0.0009320250283150481, 0.0009256153034095955, 0.0009183579825133137, 0.0009152117660795795, 0.0009120522802637818, 0.0009050207120025012, 0.0009005974009058732, 0.0008969695981796495, 0.0008907951766997897, 0.0008855314237963299, 0.0008817192626413354, 0.0008759654607843832, 0.0008722872378652937, 0.0008671265405750243, 0.0008616476430316785, 0.000857733427302262, 0.0008550681009978357, 0.0008487199877433677, 0.0008460411078904334, 0.0008399411488307038, 0.000833129498706306, 0.0008335689301451789, 0.0008277808351872598, 0.0008223784348562973, 0.0008196835800164426, 0.0008164535109006887, 0.0008136394522007867, 0.000808190957936849, 0.0008039111785583941, 0.0007996605619616493, 0.0007950913573747868, 0.0007912388943570387, 0.0007892382104268236, 0.0007860025700074331, 0.0007805196740135519, 0.0007758963099077125, 0.0007731626693142625, 0.0007701675684495749, 0.0007664233075162675, 0.0007626625954484965, 0.0007606379120679871, 0.0007558219258606182, 0.0007509278956860778, 0.0007472269436485016, 0.0007459584805743233, 0.00074212281272415, 0.0007398553264910059, 0.0007356414402166914, 0.0007315567095831952, 0.0007292043836616789, 0.0007239569866482659, 0.0007216955275347132, 0.0007186835176544596, 0.0007144239566983448, 0.0007119245298495755, 0.000709177886568907, 0.000707065392043378, 0.0007041282707553146, 0.0006999484356876427, 0.0006980318866514044, 0.0006941818574851055, 0.0006922040816989205, 0.0006867835891531986, 0.0006847227571795926, 0.0006804993344070406, 0.0006793442988367744, 0.0006751824183590903, 0.0006733367972075896, 0.0006719841319775218, 0.0006685276043531445, 0.0006649741368722862, 0.0006626355227797045, 0.0006601549464811332, 0.0006557437246230033, 0.0006543188718914834, 0.0006517836235888884, 0.0006470492769439034, 0.0006447117486717318, 0.0006433293240436603, 0.0006401105983341348, 0.0006367479653601388, 0.0006345306564103173, 0.0006335243221699803, 0.0006306613007773716, 0.0006273677749589387, 0.0006257421633618468, 0.0006219181462845782, 0.0006205577479283827, 0.0006173608385663035, 0.0006160408532862315, 0.0006130986459819709, 0.0006122105697984353, 0.0006080989214689699, 0.0006065489080240999, 0.0006044538620439255, 0.0006012566341132791, 0.0005990171073719448, 0.0005960899817908825, 0.0005953313794739638, 0.0005908780845605056, 0.0005904718385682935, 0.0005870452764148174, 0.0005863738591586388, 0.0005833503427733977, 0.0005809865838580611, 0.0005790659808018172, 0.0005768396756188849, 0.000574693801957802, 0.0005726395095011299, 0.0005710154303976059, 0.0005677931300523298, 0.0005668554351180457, 0.0005639378354819963, 0.0005613238265474389, 0.0005598137220287924, 0.0005581044919623987, 0.0005557650921393508, 0.0005540662828629953, 0.0005526012145441896, 0.0005493044843937038, 0.0005474005137019233, 0.0005463291851405548, 0.0005441504494996418, 0.00054238235190162, 0.0005407854318970256, 0.0005389817003905388, 0.0005363530603922513, 0.0005340506307167488, 0.0005332695500933346, 0.0005303928429338853, 0.0005294555613517862, 0.0005273273797556968, 0.0005258909083866712, 0.0005232914512250749, 0.0005215913800228146, 0.0005199270144961451, 0.0005190177080404723, 0.0005163748838962121, 0.0005147643953991311, 0.0005134352291303846, 0.0005105972607610667, 0.0005089897212062364, 0.0005080790450199614, 0.0005058560318184225, 0.0005042586824072615, 0.0005026199457606116, 0.0005014314109772329, 0.0004975988924669371, 0.0004983441547092558, 0.0004962117429933552, 0.0004946688919104408, 0.000492811910777481, 0.0004915798621086651, 0.0004892631643782556, 0.0004883294658370473, 0.0004865303728407208, 0.00048374249879588166, 0.0004829569878825429, 0.0004823708011882767, 0.00048037459537113845, 0.0004772252810805142, 0.0004770840697152631, 0.00047597840401528656, 0.00047378393063559325, 0.00047235234501537114, 0.0004710133628805266, 0.0004695397618449372, 0.00046824604786381487, 0.00046729879352054837, 0.0004657667286748672, 0.0004642817164355648, 0.0004625483352074274, 0.00046080899853219155, 0.0004595539976238688, 0.00045768535053664766, 0.00045666397366746973, 0.00045545419524262344, 0.00045388871720232276, 0.0004523176117890676, 0.0004516632358842614, 0.00045017680817943526, 0.0004484829400539401, 0.00044722042461433395, 0.0004456122894242066, 0.00044494295571534555, 0.0004434909540444446, 0.00044162446500865826, 0.0004408918949011967, 0.0004389267149972345, 0.0004375473859726924, 0.0004369675052649005, 0.00043579314222580006, 0.0004346131831184129, 0.0004325973390600405, 0.0004317593593885315, 0.00043050617886183316, 0.0004293990779123339, 0.000428090570705263, 0.00042610692503140986, 0.000425248389687269, 0.0004237561771378372, 0.0004231011286324744, 0.00042081481240532524, 0.0004209357831460352, 0.0004188524880365468, 0.00041771521446578913, 0.00041708425109199254, 0.00041620380906396787, 0.00041459204936917615, 0.00041335619526091706, 0.0004121199550068487, 0.0004115815031798604, 0.0004102115069317686, 0.00040926414916400705, 0.0004075360486637365, 0.0004068735857671276, 0.000405210451042431, 0.00040460420201088944, 0.000403075991684292, 0.00040208138411979396, 0.00040041957559698696, 0.00040033931157483, 0.00039896391761088285, 0.00039778041367085373, 0.0003970814088571378, 0.0003958230603132999, 0.0003936064248385212, 0.00039323350466763905, 0.0003926660037180791, 0.00039143844335306946, 0.00038978598809272566, 0.0003893531900721617, 0.000388235370572976, 0.0003870452333692877, 0.0003861312821597499, 0.00038419905186058164, 0.00038434408518407063, 0.0003829375117764187, 0.00038204633483036567, 0.0003803023511082486, 0.00038025351520314387, 0.0003792840019708166, 0.0003781381646797281, 0.00037708510421627513, 0.00037587154525369236, 0.00037540532340604217, 0.0003736265447826999, 0.0003729673666131461, 0.00037207622445677656, 0.0003707889144226494, 0.0003698898254022562, 0.0003691942880244786, 0.000368657058530476, 0.0003670258939608407, 0.00036619924904993676, 0.00036522977890384096, 0.00036458729614851157, 0.00036370749133388596, 0.00036300301993930854, 0.0003618816312188997, 0.00036090609468221636, 0.0003597675482458674, 0.00035908035815984365, 0.0003583530216200591, 0.0003577036102596338, 0.00035672229856749735, 0.00035520387186582764, 0.00035487342580809887, 0.0003538928150332765, 0.00035320031629384373, 0.0003522761492856645, 0.0003510205114247545, 0.0003502799035729775, 0.0003496415272628539, 0.00034861951751160805, 0.00034802494311401944, 0.0003469030306702786, 0.00034621027319803235, 0.00034523079093432327, 0.0003442729575750197, 0.0003437193238210507, 0.00034278670610972975, 0.00034208199994477915, 0.00034131617228984844, 0.0003403083977293993, 0.00033948471304992957, 0.000338984086071946, 0.00033823068573148165, 0.00033727581443574194, 0.00033640201405449235, 0.000335457086227161, 0.00033431067556008285, 0.00033407161093255885, 0.00033348658823022486, 0.00033199017938919203, 0.00033201968755358044, 0.0003306339713958811, 0.00033011108417464876, 0.00032946773374152843, 0.00032852982420268027, 0.0003279415945305004, 0.00032695292342983134, 0.00032625554430136105, 0.00032552206809823996, 0.00032431976512263343, 0.00032407164166400784, 0.0003230671234850509, 0.0003226212474523299, 0.0003217752880869469, 0.00032085886021677843, 0.0003205458114729775, 0.0003197605729426224, 0.00031883784284716417, 0.00031820214228332587, 0.00031770920778794457, 0.00031609072085280116, 0.0003159779956233611, 0.00031532199922778165, 0.00031488067815003734, 0.0003134019342947785, 0.0003135196226630678, 0.00031256592516975466, 0.0003114969410833363, 0.0003111903783963328, 0.0003105468776912825, 0.0003097550700542371, 0.00030870249136284164, 0.00030845653313222953, 0.0003079975535533563, 0.000306899232331754, 0.0003060717657902122, 0.0003058513352905597, 0.00030472966862023297, 0.0003047849556724813, 0.0003034950576961061, 0.0003028769558620326, 0.0003024724386619274, 0.000301858471895649, 0.0003010949120198466, 0.00030012713879253754, 0.00029916120182852995, 0.0002990591998271389, 0.0002985015586284779, 0.00029764737275152697, 0.0002973818462457274, 0.00029654505564914995, 0.0002960993569823221, 0.0002953655276022644, 0.00029481449876338434, 0.0002940096627904059, 0.0002934538111512571, 0.00029289436930074686, 0.00029230948585896735, 0.00029130629308140026, 0.0002911308752148756, 0.00029046605913405444, 0.0002895684406556806, 0.00028905912854593414, 0.0002888684230082911, 0.0002879447318834423, 0.0002871669845468337, 0.0002869963349200191, 0.0002861746619943517, 0.0002854650179532854, 0.0002853729670438317, 0.0002844860948533802, 0.00028398120128101566, 0.000283118945210641, 0.00028276598508123857, 0.0002823905363596661, 0.000281533763268951, 0.0002809460554167202, 0.0002804678329232028, 0.00028003945009328154, 0.0002793521156746716, 0.00027881922981493073, 0.00027791318192839755, 0.0002776297424147908, 0.00027702659898134384, 0.00027657110169399836, 0.00027600298405058274, 0.00027527148613783935, 0.00027473267612465217, 0.0002738215074852543, 0.0002739609867077064, 0.0002729981399974406, 0.00027260626455769693, 0.0002721470905748167, 0.00027144109004363296, 0.00027096157518542914, 0.00027061651482252337, 0.0002697639932273053, 0.000269458015635846, 0.0002689138782426497, 0.00026827115390189247, 0.00026798145269958223, 0.00026748850309555173, 0.0002668295792807811, 0.00026613441446718156, 0.00026580032656524583, 0.00026521064286524166, 0.00026460385657135294, 0.00026415918648174376, 0.0002637279291838392, 0.0002634336224920896, 0.00026219476721894115, 0.0002622984874927568, 0.00026172385306596623, 0.0002612225590917395, 0.00026073645819644516, 0.00026029736036320845, 0.0002596162367446671, 0.00025923035553717473, 0.000258807805952325, 0.0002581880156578578, 0.00025769634100806133, 0.0002573485040119531, 0.0002566418759767875, 0.0002561301738472963, 0.0002559132283585157, 0.00025514409922104166, 0.00025496783895430277, 0.00025442200231783594, 0.0002539800692762337, 0.00025340987686657237, 0.0002530257732344386, 0.0002523923705707247, 0.00025198547702012303, 0.0002516607028260675, 0.00025087073235670234, 0.00025091604210054186, 0.0002499105762506796, 0.0002496484394345586, 0.0002494363947099861, 0.0002488617162373619, 0.00024807479719153494, 0.0002479607720769863, 0.0002475705588684889, 0.00024698549438457226, 0.0002465470274656051, 0.0002461819920083409, 0.00024545506616259634, 0.0002452056993579485, 0.0002448775595545598, 0.00024391152611349771, 0.0002439201188120208, 0.00024321853645970512, 0.0002431650783071362, 0.00024254237410017035, 0.0002421111692944772, 0.0002417124661273912, 0.00024127737234995786, 0.0002409996044550482, 0.00024031865157504958, 0.00023996720244466254, 0.0002395723862570236, 0.00023892812416325172, 0.0002386332240764683, 0.000237953163460728, 0.00023776032052381168, 0.0002374700768734215, 0.00023701341839654097, 0.00023638311664843316, 0.00023641940224167256, 0.00023570280046912492, 0.00023492814417368872, 0.00023491834546811438, 0.00023474426695685698, 0.00023399543874210357, 0.00023397028731464076, 0.00023318424962663186, 0.00023298392550841147, 0.0002323802927532744, 0.00023218475478982488, 0.00023184151096778056, 0.00023130459225409794, 0.00023100553733678688, 0.00023060139355673214, 0.00023023604023192235, 0.00022974478380180822, 0.00022942816765084235, 0.00022893584095744283, 0.00022844488572968421, 0.00022823951997345186, 0.00022769832778672357, 0.00022740161158926262, 0.00022702725466607632, 0.0002265825548192287, 0.00022618932339635005, 0.00022547182335127996, 0.0002255922912720815, 0.0002250227036406116, 0.00022476948903002144, 0.00022438272342344115, 0.00022388660092828399, 0.00022351428759393837, 0.00022321276768256837, 0.0002229346245542819, 0.00022246546000908533, 0.0002221781363168963, 0.00022177067156314934, 0.0002212064715181796, 0.00022104934182945376, 0.00022059734220408227, 0.00022026117367215174, 0.000219722489542517, 0.00021956929377803174, 0.00021924917588441418, 0.00021878609365239755, 0.00021846472756273746, 0.0002181073386480392, 0.00021765012675928593, 0.0002174393766310819, 0.00021695956107353236, 0.000216884992299948, 0.0002164522002318184, 0.00021593134634810933, 0.00021556194510770392, 0.00021520615351509775, 0.00021503308541747875, 0.00021451640451642363, 0.00021421532504490415, 0.0002139996896545, 0.0002135156237132397, 0.000213262539469504, 0.00021283595460858844, 0.00021226983720129056, 0.00021224695042361218, 0.00021182804986523489, 0.0002114206729481225, 0.00021111761965807575, 0.00021076039338918187, 0.0002104625021521045, 0.00021002696673656137, 0.00020977036530893874, 0.0002094437179449713, 0.00020902989261040023, 0.00020863207798705474, 0.0002084989182236375, 0.00020817328131037983, 0.0002078722651049887, 0.00020737857843246133, 0.00020712811392306445, 0.00020685910825499104, 0.00020641251488050236, 0.00020627864887965805, 0.00020582456473042517, 0.00020569991091237702, 0.00020522275671592163, 0.00020503929607776665, 0.00020450593728978342, 0.0002042567670199915, 0.0002038318064649734, 0.00020338008221410555, 0.00020332440527548101, 0.0002030010399319669, 0.00020270935096239147, 0.0002023701254077229, 0.00020213576706215028, 0.00020173286279778562, 0.0002012964493734207, 0.00020109688204787563, 0.0002008889125122645, 0.00020057469410019024, 0.00020038688484956188, 0.00019998972229202632, 0.00019933166505740966, 0.0001994093072213919, 0.0001989222301119232, 0.0001987029882740714, 0.00019846810866484788, 0.0001982184597971776, 0.00019782116525360986, 0.00019741406600765762, 0.0001972853089062099, 0.00019697568306081573, 0.00019664139399489737, 0.00019631668389820335, 0.00019598648592805053, 0.00019565900983593327, 0.00019542431000315, 0.00019504851890972218, 0.00019489458512002262, 0.00019448402002283178, 0.0001942196790667931, 0.00019399143970391701, 0.00019376188099167754, 0.00019336309602327145, 0.00019313074515523945, 0.00019282153675682424, 0.00019256085949691956, 0.00019242196798899868, 0.0001918544664650715, 0.00019171134212297858, 0.00019152979224562708, 0.00019120469306157636, 0.00019089578954582483, 0.00019054417354637346, 0.0001902135425829646, 0.00019000254740763486, 0.00018967789627112334, 0.0001894867241590011, 0.00018899501593965578, 0.00018903823859538942, 0.00018872605301919283, 0.00018841862468600348, 0.00018814194382166485, 0.00018785561076095547, 0.00018751396434539438, 0.00018717617329959069, 0.00018709755515565262, 0.00018670389934848685, 0.00018655195535999998, 0.0001861454356689431, 0.00018600584376400064, 0.00018571997145407456, 0.00018547693961913343, 0.00018508551237213783, 0.00018490335737701238, 0.00018452908453620628, 0.0001843814495065743, 0.0001841508718900684, 0.00018389993318248325, 0.0001836235650141186, 0.00018343448881359117, 0.00018304982786916449, 0.00018280394797403214, 0.00018250338320254637, 0.00018220335380168015, 0.00018205018093848225, 0.0001818606761398082, 0.00018149232612676278, 0.00018121021114758662, 0.00018115205440140633, 0.00018081004655300602, 0.0001805033683556682, 0.00018021238847004402, 0.00017998256314555522, 0.0001798003952623309, 0.0001794567020587484, 0.000179304135995487, 0.00017898437481150608, 0.00017864029162086345, 0.0001786505251612785, 0.00017825465869096983, 0.00017804525739022618, 0.00017767193667018213, 0.00017753814212604388, 0.00017727050316281162, 0.000177073972221064, 0.000176750320929204, 0.0001765221866759674, 0.00017624321744054327, 0.00017614830255204813, 0.00017600091812625845, 0.00017562867785400727, 0.00017528536577429083, 0.00017506927409950872, 0.0001749027852029717, 0.0001747049408845977, 0.0001743789218203915, 0.00017423643428204135, 0.00017396723408253696, 0.0001737946469026402, 0.00017351687545595713, 0.0001732595473253819, 0.00017296708125660604, 0.00017273258981942045, 0.00017258267200145856, 0.00017232148921183683, 0.00017213975495696115, 0.00017183409501623714, 0.00017158194904996312, 0.00017146985603376188, 0.00017107088175989085, 0.00017095534244035331, 0.00017067447346739092, 0.00017042376911835316, 0.0001703129272339652, 0.00016995288793992101, 0.00016986407026053503, 0.00016957653728105271, 0.00016934435131191113, 0.00016913279188605893, 0.00016887633606041183, 0.0001685724679144182, 0.00016847007351513573, 0.00016829737928527068, 0.00016805541353226753, 0.00016781204608359938, 0.00016761980696343906, 0.00016742897749862825, 0.000167007636333904, 0.00016693007245812907, 0.00016658015991780672, 0.00016660451052835393, 0.00016628455552724594, 0.00016608601017892966, 0.0001658253891871695, 0.0001655885181062023, 0.00016550820877497566, 0.000165216389284789, 0.00016496578786324298, 0.00016479044901802808, 0.00016457937658921414, 0.0001643003201496948, 0.0001641855102098191, 0.00016388399457957804, 0.00016372183557795, 0.00016345313816293108, 0.00016331871645742051, 0.00016314001588044153, 0.0001628853015730627, 0.00016267272828000045, 0.00016234611742170556, 0.00016215528196724213, 0.0001620182177305575, 0.00016184245604329087, 0.00016163436888525003, 0.00016117663708978586, 0.00016116019704797205, 0.00016101122951406665, 0.00016082784264678432, 0.0001605132002500298, 0.0001604140827634808, 0.00016014626095236888, 0.00016004162624884088, 0.00015980990230854295, 0.00015959111093102744, 0.00015939992383379813, 0.0001591638702516415, 0.00015901002867780298, 0.00015870622439486938, 0.0001585703398727034, 0.00015839357751328245, 0.00015813052467085242, 0.0001579808507650071, 0.0001577638680724244, 0.00015752817631370182, 0.00015733205978320323]\n",
      "[0.9343999924262365, 0.9457999929289023, 0.9542166600823403, 0.959299994101127, 0.9643833276033401, 0.967349994579951, 0.9702166616519292, 0.9720499951243401, 0.9739499955276648, 0.9757666623493035, 0.9769499957164128, 0.9784499959846338, 0.9792666627864043, 0.980933329820633, 0.9815166631440322, 0.982966663479805, 0.9833833299775918, 0.9846166635155678, 0.9853333303133647, 0.9863666640619437, 0.9871999973853429, 0.9876166642407577, 0.9880333309074243, 0.9884333309531211, 0.9892666643559933, 0.9895999977389971, 0.9904499980111917, 0.9907166646420955, 0.9913333314756553, 0.9914999981721242, 0.9924833317001661, 0.9922333316405614, 0.99291666512688, 0.99306666508317, 0.9933166651924451, 0.9938166653017203, 0.9943666654328506, 0.9942499987284342, 0.9947166654864947, 0.9953499989410242, 0.99534999893109, 0.9954833323160808, 0.9956666656831901, 0.996099999109904, 0.9959999991059303, 0.9966499992112319, 0.9966666658918063, 0.9969999993244807, 0.9968499992489814, 0.9971999993721644, 0.9973666660586993, 0.9975999994476636, 0.9975333327651024, 0.9978499995172023, 0.998149999598662, 0.9981333328882853, 0.9983333329459031, 0.9984333329796791, 0.998599999666214, 0.998649999678135, 0.9986333330074946, 0.9986666663487752, 0.9989166664083798, 0.9988666664063931, 0.9988833330969016, 0.9989666664203009, 0.9991833331485589, 0.9992333331505457, 0.9992666664918264, 0.9992333331604799, 0.9993666665156682, 0.9992666664918264, 0.9993999998569488, 0.9994166665275892, 0.9994499998688697, 0.9995499998927116, 0.999516666551431, 0.9995999999046326, 0.9996333332459132, 0.9995499998927116, 0.9996999999284745, 0.9996166665752729, 0.9997166665991147, 0.999783333281676, 0.9997666666110356, 0.9997666666110356, 0.9997666666110356, 0.9997666666110356, 0.9998499999642372, 0.9998166666229565, 0.999783333281676, 0.9997999999523163, 0.9998333332935969, 0.9998999999761582, 0.9998999999761582, 0.9998499999642372, 0.9999333333174387, 0.9998833333055178, 0.9998999999761582, 0.9999333333174387, 0.9999666666587194, 0.9999333333174387, 0.9998833333055178, 0.9999166666467985, 0.9999833333293597, 0.9999499999880791, 1.0, 0.9999833333293597, 0.9999666666587194, 0.9999666666587194, 0.9999833333293597, 0.9999666666587194, 0.9999833333293597, 0.9999833333293597, 0.9999666666587194, 0.9999833333293597, 1.0, 0.9999833333293597, 0.9999833333293597, 0.9999833333293597, 0.9999499999880791, 0.9999833333293597, 1.0, 0.9999833333293597, 1.0, 1.0, 1.0, 1.0, 0.9999833333293597, 1.0, 1.0, 1.0, 0.9999833333293597, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.20446424773475155, 0.17382007863395849, 0.15122401337011251, 0.13994085565628483, 0.1318547553595854, 0.11723883335091523, 0.1126194780060905, 0.10858692279102979, 0.1046956110453757, 0.10162703796404822, 0.09635724775285053, 0.09488819928259909, 0.09177362670921138, 0.09040090553696792, 0.09095060922495031, 0.08876624387745688, 0.08851873690976209, 0.0885921582638257, 0.0850230369479541, 0.08546045507801682, 0.08278692135202073, 0.08428892210337108, 0.084477936714733, 0.08467132967482394, 0.08068573191069754, 0.08252980389448566, 0.08132389109768337, 0.0810342135191213, 0.08173989427816196, 0.08405965618672644, 0.0818268554334345, 0.08209344706453271, 0.08254085009897154, 0.08157231402387106, 0.08074908009915635, 0.0823436554986747, 0.08357100676216214, 0.08211217831061549, 0.08401495628424345, 0.08587252998462862, 0.08298274664791233, 0.0825480871639179, 0.08444426643241013, 0.08328752868137053, 0.08371455617674428, 0.08386148588787865, 0.08513038175689712, 0.08537286514576409, 0.08866850070754446, 0.0855401001040542, 0.08583387378758311, 0.08616528554825652, 0.08539106226058767, 0.08831121624345463, 0.08673008164750672, 0.08616076081593337, 0.08643099343907443, 0.08666267603744518, 0.08997134314844357, 0.08886418917658455, 0.08737470456842436, 0.08951388043811369, 0.089859560624891, 0.09024833143603252, 0.09091541562560229, 0.08955218518302979, 0.09109608027039047, 0.09105188065841856, 0.0916891661690774, 0.09210283086798575, 0.09052574451903184, 0.09245873467765807, 0.09234937985177626, 0.09259714549362508, 0.09445569431606958, 0.09345211161057716, 0.09212724317263696, 0.09290425930416353, 0.09376102109815787, 0.09340330075342126, 0.09482814210757044, 0.09533575209336709, 0.09599916499871156, 0.09417930020020049, 0.09578425784735799, 0.09521132916958981, 0.09613984729590512, 0.09613391582442386, 0.09606340179658632, 0.09755024622892233, 0.096399740080063, 0.09632873838822291, 0.09792095212855403, 0.09740778417288566, 0.09841113062673396, 0.0990765768613524, 0.09920197060514686, 0.09790298409062582, 0.10052693964586212, 0.0992360111761457, 0.09892574851323215, 0.099102355170306, 0.10029559718817711, 0.09984997619027305, 0.10023498785287628, 0.10092821502826149, 0.10059370264026517, 0.1012913437600775, 0.1007014368102267, 0.10187017656084953, 0.10109946427504907, 0.1017490530261109, 0.10197155173635193, 0.10190214137662773, 0.10199817460796023, 0.10196747539523966, 0.10216304528457268, 0.10284993837952718, 0.10265925006166535, 0.10335745861024223, 0.10392731078516002, 0.10303034152904947, 0.10343836245285475, 0.10305945530154377, 0.1036330882904833, 0.1040416515905938, 0.10528388438663223, 0.10401575944355732, 0.10494556004870774, 0.10534096437775997, 0.10592695326731298, 0.10551231316292538, 0.10528651220973136, 0.10522872357381857, 0.10543280832970961, 0.1055748469429894, 0.10653467979871094, 0.10639621821741257, 0.10628158380923287, 0.10666338897390398, 0.10629573458145578, 0.1064693495866449, 0.10672629376066979, 0.10694252306908411, 0.10682707253340937, 0.10652583167595414, 0.10766494599262771, 0.10766916330121983, 0.10779801147596613, 0.10817603298656854, 0.10831996574762279, 0.1081515566921986, 0.10888487920332882, 0.10805844265359715, 0.10982808553341572, 0.10965253350611852, 0.10924680478393893, 0.10966324928567638, 0.10933920631800781, 0.10982865961015509, 0.10937382472639592, 0.1090926309375521, 0.11010010304385259, 0.11028894100808061, 0.10999829030477312, 0.11050401279648266, 0.1106359898885911, 0.11015940229358433, 0.11080965328947243, 0.11093459187375888, 0.1109817188333212, 0.11069699392143577, 0.11100303188076725, 0.11110500437822572, 0.11125173083798082, 0.11177990698574095, 0.11207880331773218, 0.11179700214277509, 0.11161621360033216, 0.11216480733970004, 0.11168556615349691, 0.1118275055993445, 0.11209872381038251, 0.1129834777336283, 0.11189139189846532, 0.11243375351132717, 0.11295799734173292, 0.11284857201701272, 0.11358290028399742, 0.1130101517331068, 0.11347050836924705, 0.11370071760773957, 0.11372394387749557, 0.11352019104769097, 0.1138922696080491, 0.11395161408380158, 0.11389650018176276, 0.11389459677093727, 0.11430269708835761, 0.11463168555833797, 0.11420848508026515, 0.11424222585837836, 0.11520760740374894, 0.11435600925852493, 0.11483838063812125, 0.1153526131924888, 0.11523061615026704, 0.11516365910113675, 0.11557668366003586, 0.11506713177009507, 0.115201889745696, 0.11536582233503925, 0.11564288375587461, 0.11580755247443353, 0.11570234280533805, 0.11595326902710404, 0.11599432526828447, 0.11586393458732482, 0.11574448152015848, 0.1164356377827927, 0.11614967044916566, 0.11610199646831589, 0.11648453079553892, 0.11644910776372383, 0.11688277811311058, 0.11672903061730722, 0.11657217441271218, 0.11710817041889168, 0.11695129632156749, 0.11746083411207706, 0.11759392164483995, 0.11769334976617757, 0.1177524282886558, 0.11782563036456241, 0.11763920842991313, 0.11718953259876648, 0.11810593401466025, 0.11790899068504136, 0.11812230008578263, 0.11792094366519325, 0.11812511538369824, 0.11826352451538429, 0.11811186761368761, 0.11854926671163289, 0.11860593565383978, 0.11841718410848566, 0.11904919298879822, 0.11861489013122468, 0.1184771302191626, 0.11899639161055565, 0.11908248140481209, 0.11952104849832662, 0.11890007939175343, 0.11898083078112812, 0.11935553272011079, 0.11924812390583374, 0.1194642956946471, 0.11928707523945654, 0.11931847443602067, 0.12003803739711384, 0.11963423538113725, 0.119888300826282, 0.12023477505967307, 0.11997705124793888, 0.12014902355247577, 0.12035848831312271, 0.1205769142978477, 0.11997351242040755, 0.12026852603827443, 0.12059494248974509, 0.12039282855198533, 0.12057286791262789, 0.12035504350001008, 0.12034814796525355, 0.12090417170284912, 0.1208541975840119, 0.12114227464985104, 0.12096273109539331, 0.12121369683670978, 0.1212402609027591, 0.12118768490134421, 0.12113542073854239, 0.12129475962604237, 0.12192887040427122, 0.12151021937853632, 0.12159247437892409, 0.12162861124051731, 0.12161587733600245, 0.12139291569710131, 0.1219308262508565, 0.12168224825895124, 0.12253391460593384, 0.12219630494881753, 0.12199456824810527, 0.12254568906790642, 0.12258213898333113, 0.12211363334066072, 0.12251633094938948, 0.12247660455603654, 0.12248287769404846, 0.12267709336433559, 0.12251461621407365, 0.12268939404624048, 0.12313193872890683, 0.12275773017051397, 0.12252716554762355, 0.12279798335211445, 0.1229037857356737, 0.12277385624635008, 0.12331769108000788, 0.12315852921880768, 0.12323424113169593, 0.12332227987052606, 0.12329968040531389, 0.12335378316686285, 0.12364916864624888, 0.12323174037020944, 0.12353343993145463, 0.12345535611848978, 0.12329545842857945, 0.12347731798560385, 0.12372669683419221, 0.12411444869863344, 0.12394686077260039, 0.1246136919596978, 0.1238856798068899, 0.12427431644848957, 0.12438498929421848, 0.12410975662251433, 0.12411933341618539, 0.12424750019658556, 0.1242330173872463, 0.12453005707693378, 0.1243967992414985, 0.1245275648766842, 0.1244401282740826, 0.12460805446871896, 0.12471887111091184, 0.12487667207594288, 0.12498510470107983, 0.1248536898085242, 0.12496191390876993, 0.12507937679927103, 0.1248638983545115, 0.1253159962324882, 0.12507932404316235, 0.1253306804958582, 0.12513392481649502, 0.12528657122919873, 0.1255089114131909, 0.1253226790918125, 0.12561126018765997, 0.1255884199143249, 0.12560833134861074, 0.12544030034919967, 0.12584618886175036, 0.1255559279089505, 0.12631115443900892, 0.1258726816474983, 0.1258999771682409, 0.12571219250337334, 0.12612830356710922, 0.126043400541301, 0.12616858685158808, 0.12619683425243355, 0.1260540024881128, 0.12615544063390702, 0.12619921446445156, 0.12643462795414886, 0.12645868086436782, 0.12648799033981392, 0.12642866093811356, 0.12635681814584307, 0.12631219322276538, 0.12647828586189122, 0.12670975420370345, 0.126868815509625, 0.12691030095236855, 0.12670582853542886, 0.12696892511899993, 0.12670970467690262, 0.12667142293549938, 0.12741654543680922, 0.12680601613073517, 0.12709147904887158, 0.12701278993266832, 0.1271874011376479, 0.12721831047015567, 0.12730527697919825, 0.1272843742348172, 0.12745346051987855, 0.12752480044180597, 0.12760327964008644, 0.1277533250372538, 0.1273494281369639, 0.1273901779481669, 0.12751008223360522, 0.12789508635874597, 0.12749340552297653, 0.12764710726190598, 0.1278086680518981, 0.12797369672128064, 0.12787325086305645, 0.1277553777808262, 0.12806583216964518, 0.12810777275464988, 0.12825413966042368, 0.12781473223258427, 0.12799376684862732, 0.12803503897163657, 0.12833417858615126, 0.1282077666778264, 0.12826293509610523, 0.1283520650581649, 0.1281093945176258, 0.12831055350767756, 0.12875894462416868, 0.12867058270590453, 0.1283274132525609, 0.12857925988043312, 0.12861367342301502, 0.1285491085151105, 0.1288446781409415, 0.12878157855791347, 0.12889008885352235, 0.12870493871037134, 0.12874762228097508, 0.12920518391154706, 0.1289164412959908, 0.12931487966178964, 0.12900530140066718, 0.1290757864563034, 0.12903950386075408, 0.1292937773551777, 0.129270780414977, 0.1296395871241308, 0.12941999158024972, 0.12918401970317558, 0.12948909705266295, 0.12952620440467957, 0.1292885477074532, 0.12967587514307916, 0.12952587897613715, 0.1296470645552543, 0.12943900322552504, 0.12968238589113468, 0.1298121364395089, 0.12990203744627934, 0.12977248300407274, 0.12982332879669267, 0.1298757234921874, 0.12968281196309353, 0.12987976646270805, 0.13004484093891955, 0.12974421512496048, 0.1299091284011497, 0.12998741126974245, 0.13002855643717215, 0.1304738677976884, 0.1299459346683786, 0.13007243665035004, 0.1299854133888655, 0.1301978698726722, 0.13008833781055867, 0.13044659193554203, 0.13067115042137964, 0.13024851971284537, 0.1304949983637603, 0.13051242548567593, 0.13054439971061935, 0.13046582323264225, 0.13053151815503128, 0.13075677681042722, 0.13055652020289243, 0.13078025704682758, 0.13070435911426234, 0.1306622404223451, 0.13089671324252503, 0.13093051366894995, 0.13066623308419562, 0.1310808746400392, 0.1309339313560517, 0.13096446614413854, 0.13097861578812736, 0.13100264863817027, 0.13122662725915546, 0.13107843676313158, 0.13127405010315896, 0.1310870180453132, 0.1311051070954723, 0.1311559619155154, 0.1313273169112705, 0.1314334836465246, 0.1314965418950896, 0.13128066825497625, 0.1312885200121249, 0.13137052418508766, 0.13157063283677534, 0.13158326634175255, 0.13175745830045743, 0.13171863144721144, 0.1314888548603606, 0.1316234490602561, 0.1317825109279346, 0.1316350788704132, 0.13177895400335052, 0.13168747204254816, 0.13165366169952253, 0.13185872395078715, 0.13205274129114455, 0.13197851850036973, 0.13198945716314847, 0.13184614186380314, 0.13177570577863082, 0.13204908495584697, 0.13216271757219505, 0.13204335215670707, 0.13226748281263737, 0.13209108562995, 0.13225506144828392, 0.13246051820559626, 0.1323936557602545, 0.13232148588879342, 0.13247409635431173, 0.13236165472251268, 0.13253941536787325, 0.1324813121228227, 0.1327792828070817, 0.13259437732786775, 0.13257145792963557, 0.13271230731417608, 0.1326051634248626, 0.13258095921536173, 0.13282634178276273, 0.13271467264442163, 0.1328849247677987, 0.1330783261174146, 0.13291506550852242, 0.13291916037655732, 0.13288002365949725, 0.1329674381080017, 0.13270370591582892, 0.13285827649187648, 0.1331054372635298, 0.1329731701375414, 0.13310691816908082, 0.13301410637115135, 0.1331037646113462, 0.13322209305028615, 0.13318880439148437, 0.13309444621590438, 0.13315089601142796, 0.13341359624752192, 0.13336357545054361, 0.1332861675172975, 0.13322591654132315, 0.1332509112931032, 0.13317756827901425, 0.13323043377308907, 0.13352654911502992, 0.13355634908739156, 0.13358913830965444, 0.1333608447576212, 0.13346291836710206, 0.133697713601444, 0.13388774433883033, 0.13344275935095354, 0.13366153858242574, 0.13362933450254907, 0.13371218147609068, 0.1336831337318258, 0.13383708398882035, 0.13385204541030024, 0.13385395722243157, 0.1340308811957843, 0.13408449733820085, 0.1340256779856877, 0.13393533063087593, 0.13411655666044042, 0.13408084525597014, 0.13426830016772434, 0.1339699600084, 0.13429135057170144, 0.13411866575579448, 0.13425873371812835, 0.1343622894393724, 0.13432457554300123, 0.134401014190899, 0.13436320348122377, 0.13423413494273345, 0.13453180954356111, 0.13427852861766998, 0.13460503279818892, 0.13458554314215948, 0.13458797707874467, 0.13444677891906676, 0.134825470855083, 0.13460819165570762, 0.13451688539960976, 0.13455288014171143, 0.1346760295398436, 0.13467376549063492, 0.13472933373716128, 0.1347903734527922, 0.13471883168852125, 0.13487530478538406, 0.13488844440659437, 0.13484441128291805, 0.13485802741275119, 0.13474223193562457, 0.13481040942787959, 0.13507829737554647, 0.13496659373187728, 0.13513985922530392, 0.1349628671088372, 0.13505717506483988, 0.13528897679898855, 0.13539683870912514, 0.1351468152293307, 0.13505840273601727, 0.13502608143199696, 0.13525707691419062, 0.13532375148730766, 0.13530742818609137, 0.135275800644661, 0.13543208120850309, 0.13532431811438547, 0.13522966812407544, 0.13515335508774334, 0.13537716117540577, 0.135230227173521, 0.13557086231196994, 0.13545073962967302, 0.1355361018627738, 0.13563423449853118, 0.13567756050325586, 0.13553821684708872, 0.1356117933653468, 0.1357403901535301, 0.1357261062458775, 0.13582206815048697, 0.1357606863859205, 0.13560811318451935, 0.13584282843427245, 0.13594505136015156, 0.1358527839431552, 0.13591994463194518, 0.13590330402649087, 0.13606133130333195, 0.1360291160636489, 0.13602431075269725, 0.13604290282002826, 0.13604378618128213, 0.13612155416166763, 0.13594191378523296, 0.1360164627895437, 0.13610052900803785, 0.13617264136624477, 0.13626754954133471, 0.13622089288563902, 0.13637491260002899, 0.1360938390396568, 0.136427384801047, 0.1361561777039227, 0.13636317445749485, 0.13639500966955698, 0.13649920020571935, 0.1364859650453785, 0.13657940016866324, 0.13640734621692507, 0.13644152804681908, 0.13651520273361206, 0.13645842982323744, 0.13635760725829005, 0.13662055362223122, 0.13634409550518314, 0.1366275118310607, 0.13651683210570795, 0.13674619115109507, 0.13665708747899888, 0.13705972520125656, 0.13668102977336027, 0.1367686423460642, 0.13687012555960967, 0.13678774839744773, 0.1369166388663534, 0.1368490179095901, 0.13673170542174073, 0.13719670376200152, 0.13704392114406228, 0.13714321143943445, 0.13687189259724808, 0.1372628414976214, 0.1370464709030539, 0.13702558813928803, 0.13713740135042862, 0.13704589359804598, 0.1372258674186806, 0.13719751601925312, 0.1370261197872144, 0.13716754104566817, 0.1372618353126531, 0.13740358776783523, 0.13736608039874587, 0.13767137001551424, 0.13745124156092084, 0.1374113351066156, 0.13739511530524312, 0.1374494887091058, 0.13744137495512715, 0.13759544916745306, 0.13765897404675986, 0.13753212992050318, 0.13760564173799542, 0.13765058400224317, 0.13770813839715115, 0.13754320574932488, 0.13761470938356776, 0.13749494654982217, 0.13779283413569587, 0.13775893484926557, 0.13756974179099657, 0.1375899751279741, 0.13768625821914862, 0.13771336944508897, 0.13786672015511015, 0.13776050875111268, 0.1378667672089952, 0.13765637735026037, 0.1378544769895457, 0.13774547816901966, 0.1378115808863987, 0.13796333850186482, 0.13797821758028783, 0.13802698559599755, 0.1380720048470319, 0.13790910933210956, 0.13815624530964896, 0.13816058081826724, 0.13801380946539638, 0.1381209925584296, 0.13821474520946112, 0.1383259206252431, 0.1381252377095493, 0.13802761685473475, 0.13822370371551268, 0.13840181680133368, 0.13826722883796913, 0.13842474604165034, 0.13826281488500433, 0.13819683427229437, 0.13840406055512103, 0.1383655501699533, 0.13840182237621537, 0.13844455693192007, 0.13843860409752692, 0.1384379885586159, 0.13847867166865716, 0.13853571817603533, 0.13841549456085164, 0.13849410473617593, 0.1385456609919033, 0.13863116783995544, 0.13868666836808055, 0.13869033100456266, 0.13868657913408758, 0.138680044293815, 0.1387277904750204, 0.1386426773276995, 0.13880648288262282, 0.13882553193744637, 0.1386923460118549, 0.13893129007821536, 0.13874721099746243, 0.13892388282789142, 0.1388340290142061, 0.13898855081731085, 0.1389660986161106, 0.13890143602912236, 0.13903820331551286, 0.1391346882836422, 0.1390846279163912, 0.13895231362626115, 0.13897502863153163, 0.13910019311413624, 0.1390964220676458, 0.13905505336815507, 0.13921491886261217, 0.13910203490073375, 0.13910674902419684, 0.13910552730374035, 0.13912843065408304, 0.13915518471976873, 0.1393796415473886, 0.13931429997186248, 0.13926607150725823, 0.13936931586147308, 0.13936576044599666, 0.13934488707767165, 0.1393980276638054, 0.13950749587775393, 0.1395525979893689, 0.13959602893748746, 0.13943668571874046, 0.13959136314433873, 0.13943108481571018, 0.13955351254790332, 0.1395231587085711, 0.1395534832636607, 0.139571373633488, 0.13952172011271483, 0.13952353573208284, 0.13963524523761361, 0.1398521985222195, 0.13979227087163268, 0.1395839448678107, 0.13988591596785183, 0.13966210995407935, 0.13973859520073925, 0.13978436043490805, 0.13987235589759545, 0.13978961367206644, 0.1400186975503696, 0.1398205026502352, 0.1399316809611912, 0.1399517775188119, 0.1399947468296724, 0.14005605556617695, 0.13983168380066358, 0.13999679149048638, 0.13993064800900654, 0.13998011178726072, 0.14007859466136544, 0.14009212962464646, 0.1400225099203318, 0.14006511863304058, 0.14000303629968677, 0.14018036306181528, 0.14023913139569896, 0.1400223972571929, 0.1403161412233746, 0.14015850087477222, 0.1402057899595838, 0.1401335340193047, 0.14029092749688882, 0.1403960502284409, 0.14032481560829896, 0.1404175079742448, 0.14021907406434408, 0.14033064961378933, 0.14042540406982149, 0.14043362430453665, 0.14063486206014839, 0.14041017938053213, 0.14050520281783407, 0.1404743117638575, 0.14049004991339803, 0.14070818239125799, 0.1405622245612899, 0.1405616489468218, 0.14046509537586807, 0.14056344304420562, 0.1406462183561486, 0.14060483822408704, 0.14061986823679473, 0.14076399023377997, 0.14068480831513422, 0.1407580570282854, 0.14088978685390519, 0.1408987035315266, 0.14078902506791163, 0.14082957506956598, 0.1408184719448677, 0.14082488070812857, 0.14081833926566098, 0.14101039802708715, 0.1409775427757787, 0.14098521461566718, 0.14091512463717282, 0.14110394814275568, 0.14085757692777157, 0.14104834202803662, 0.14104753232707115, 0.14100806452791845, 0.14110169785678192, 0.1410194206918812, 0.1410940037750069, 0.14100501610157926, 0.14118980861567293, 0.1410924546197929, 0.14121744597703598, 0.14124794134019458, 0.14123829749724792, 0.1411622940755672, 0.1412446768777097, 0.1413714124501864, 0.14122955182565325, 0.14116882460381075, 0.14121900377961277, 0.14138090013333343, 0.14147561788614965, 0.14142462366071507, 0.141598710243121, 0.14144542548305575, 0.14145827419407492, 0.14141836853110332, 0.1415397567358703, 0.14158837040818598, 0.14164158788426762, 0.14140166727292494, 0.14167757203624107, 0.1415867744346742, 0.14157407001372257, 0.14165473460468483, 0.14159480578155284, 0.14162940348129122, 0.1415489975044408, 0.1416208163029282, 0.14171133239275926, 0.1416842276925792, 0.14180442961281212, 0.14170680450073012, 0.1417890837031188, 0.14180226388599854, 0.1417930928021444, 0.14183384542704378, 0.14169683839359312, 0.14190606931045535, 0.14180543567556106, 0.14181380336568922, 0.14194248439762397, 0.14200359614196512, 0.1418725533686177, 0.14189204323170865, 0.14202524073105086, 0.14206383255218186, 0.14204927629915068, 0.14197984818141948, 0.14213237493547973, 0.14218452664804712, 0.142080552461658, 0.14219419849941947, 0.14202146738223012, 0.14204966793795404, 0.14217486385467468, 0.1422423730652055, 0.1422458812420573, 0.1421955557572818, 0.1421823132294172, 0.14223751506885002, 0.14218712156513094, 0.14230356852899648, 0.14233485387871272, 0.14240231527385583, 0.14223969668409772, 0.14233089509217034, 0.14234071897884626, 0.14227784410556793, 0.1423110788412235, 0.14221351378717667, 0.14240077688343897, 0.14241907110568303, 0.14242144465520656, 0.14235595979111573, 0.14245354559170947, 0.14242792857054656, 0.14252232370154813, 0.14250291223770192, 0.14250428653139144, 0.14260957852343972, 0.14254958703115692, 0.14271757292886403, 0.14266567475449723, 0.14257847813448815, 0.14259267279299492, 0.142578100418207, 0.14257217908365843, 0.1427526433597604, 0.14268833089423313, 0.14273189725918592, 0.1426870201956329, 0.14271500935876133, 0.1427410091296197, 0.142825555618987, 0.14289142068246957, 0.14296726216928524, 0.14284267550060534, 0.14277281976490278, 0.14284637890501575, 0.14289312931267883, 0.1429068202039412, 0.1428935983119109, 0.14274969793634276, 0.1429452764292528, 0.14309106970370186, 0.14311845250856206, 0.14298963165741121, 0.14299390640074505, 0.14307100616562135, 0.14304847172833182]\n",
      "[0.9404999932646751, 0.9504999941587449, 0.955899994134903, 0.9603999948501587, 0.9612999947071076, 0.9665999950170517, 0.9682999956011772, 0.9678999952673912, 0.9707999954223633, 0.9706999952793122, 0.971899995625019, 0.9730999956727028, 0.9720999956130981, 0.9742999958395958, 0.9743999956250191, 0.9732999958992005, 0.9725999954342842, 0.9730999957919121, 0.9748999960422516, 0.9743999957442283, 0.9753999958634376, 0.973999995648861, 0.9738999955654144, 0.9751999956965447, 0.9756999955773353, 0.9748999953269959, 0.974899995803833, 0.9754999958872795, 0.9766999961733818, 0.9757999957203866, 0.976599995970726, 0.9756999956965446, 0.974699995815754, 0.9760999960303307, 0.9765999960899353, 0.9759999960064888, 0.9761999958753586, 0.9767999961972237, 0.9762999958992005, 0.9752999958395958, 0.9763999961018562, 0.9766999959349633, 0.9757999959588051, 0.9765999962091446, 0.9764999961853027, 0.9759999960064888, 0.9762999960184098, 0.9763999960422516, 0.9755999959111213, 0.9768999961018562, 0.9768999963402748, 0.9760999962091446, 0.9776999962925911, 0.9765999960303307, 0.976499996304512, 0.976799996137619, 0.9771999962925911, 0.9770999961495399, 0.9766999961137771, 0.9769999962449074, 0.976499996304512, 0.9766999961137771, 0.976499996125698, 0.9763999961018562, 0.9759999961853028, 0.9764999964237213, 0.976799996316433, 0.976799996316433, 0.9768999962210655, 0.9767999962568283, 0.9761999962329865, 0.9762999963164329, 0.9765999963283539, 0.9766999962925911, 0.9769999962449074, 0.9766999964118004, 0.9770999964475632, 0.9766999964118004, 0.9774999963641167, 0.9770999962687492, 0.9770999962687492, 0.9763999963402749, 0.9772999963164329, 0.9766999963521957, 0.9767999961972237, 0.9767999961972237, 0.9765999963283539, 0.9768999963998795, 0.9770999964475632, 0.976799996137619, 0.9767999963760376, 0.9769999963045121, 0.9758999962210655, 0.9765999962687493, 0.9768999964594841, 0.9769999964237213, 0.9763999963402749, 0.9767999964356422, 0.9761999962329865, 0.9762999961972236, 0.9764999962449074, 0.9764999961853027, 0.976499996304512, 0.975799996137619, 0.9764999963641167, 0.9768999962806701, 0.9763999961614609, 0.9770999962687492, 0.9765999962687493, 0.9770999964475632, 0.9759999961256981, 0.9762999962568283, 0.9756999961733818, 0.9755999960899353, 0.9764999962449074, 0.9764999961853027, 0.9769999963045121, 0.9762999962568283, 0.9763999963402749, 0.9762999962568283, 0.9768999963998795, 0.9760999962091446, 0.9766999962329864, 0.9761999961733818, 0.9757999961972237, 0.9764999963641167, 0.9764999962449074, 0.9764999963641167, 0.9769999963045121, 0.9758999962210655, 0.9763999963402749, 0.976499996304512, 0.9763999963402749, 0.9763999962210655, 0.9765999964475631, 0.9761999962925911, 0.9765999963879586, 0.9754999962449074, 0.9763999963402749, 0.9765999963283539, 0.9760999962091446, 0.9762999962568283, 0.9762999963760376, 0.9760999963283539, 0.9759999963641167, 0.9763999963402749, 0.976499996304512, 0.9759999963045121, 0.9763999963998795, 0.9762999961972236, 0.9759999963045121, 0.9764999963641167, 0.9768999963998795, 0.9763999963402749, 0.9762999961972236, 0.9755999962091446, 0.9758999962806701, 0.9759999962449074, 0.9760999963283539, 0.9761999964118003, 0.9762999962568283, 0.9759999963641167, 0.9760999963283539, 0.9762999963760376, 0.9762999963164329, 0.9768999963998795, 0.9763999963402749, 0.9763999963402749, 0.9760999963283539, 0.9760999962687492, 0.9761999962925911, 0.9761999962925911, 0.9758999963998795, 0.9758999962806701, 0.976199996471405, 0.9762999963164329, 0.9760999963879585, 0.9761999962925911, 0.9756999962329864, 0.9762999963760376, 0.976499996304512, 0.9759999963641167, 0.97559999614954, 0.9760999963879585, 0.9760999963283539, 0.9759999964237213, 0.9760999963283539, 0.9755999963283539, 0.9764999964237213, 0.975799996316433, 0.9756999962925911, 0.9762999963760376, 0.9761999963521958, 0.9762999963164329, 0.975499996304512, 0.9761999964118003, 0.9760999963283539, 0.9760999963879585, 0.9756999963521957, 0.975799996316433, 0.9755999962687493, 0.975499996304512, 0.9756999962925911, 0.9758999963402748, 0.9758999962806701, 0.9757999962568283, 0.9758999963402748, 0.9761999962329865, 0.9761999964118003, 0.9756999962329864, 0.9758999963402748, 0.9756999963521957, 0.9760999963283539, 0.9763999963998795, 0.975499996304512, 0.9757999963760376, 0.9761999962925911, 0.9761999962925911, 0.9759999963641167, 0.9762999964356422, 0.9756999964118004, 0.975799996316433, 0.9762999964356422, 0.9759999963641167, 0.9761999962925911, 0.9758999963998795, 0.9758999963402748, 0.975799996316433, 0.9758999963998795, 0.9760999962687492, 0.9761999963521958, 0.9763999963402749, 0.9759999963045121, 0.9760999963879585, 0.9762999963760376, 0.9760999963283539, 0.9760999963283539, 0.9757999962568283, 0.9758999963402748, 0.9760999963283539, 0.975799996316433, 0.9760999962687492, 0.9762999962568283, 0.9757999962568283, 0.9759999963045121, 0.9759999963045121, 0.9761999963521958, 0.9758999962806701, 0.9759999963641167, 0.9758999962806701, 0.9756999962925911, 0.9761999962925911, 0.9761999963521958, 0.9757999964356422, 0.9758999962210655, 0.9758999962806701, 0.9758999963402748, 0.9758999962806701, 0.9755999963283539, 0.9762999963164329, 0.9758999963402748, 0.9759999963045121, 0.9758999962210655, 0.9755999962687493, 0.9762999964356422, 0.9758999963402748, 0.9756999962329864, 0.9754999962449074, 0.9758999962806701, 0.9759999963045121, 0.9758999962806701, 0.9758999962210655, 0.9758999963402748, 0.9761999964118003, 0.9759999961853028, 0.9759999961853028, 0.9758999963402748, 0.9763999962806702, 0.9758999962210655, 0.9758999962210655, 0.9757999962568283, 0.9761999963521958, 0.975799996316433, 0.9763999963998795, 0.9756999962329864, 0.9761999962329865, 0.9757999963760376, 0.9758999962806701, 0.9756999962925911, 0.9756999962925911, 0.9755999962687493, 0.9756999962329864, 0.9756999962329864, 0.9756999962925911, 0.9757999961972237, 0.9759999963045121, 0.9758999963402748, 0.9757999962568283, 0.975799996316433, 0.9759999963045121, 0.9757999962568283, 0.9759999963045121, 0.9759999963045121, 0.9759999963045121, 0.9758999963402748, 0.9758999962806701, 0.9760999963283539, 0.9757999962568283, 0.9756999962925911, 0.9761999961733818, 0.975799996316433, 0.975799996316433, 0.9760999962091446, 0.9757999962568283, 0.9757999962568283, 0.9757999962568283, 0.9759999963045121, 0.9758999963402748, 0.9759999963045121, 0.975799996316433, 0.9759999963045121, 0.9758999962806701, 0.9758999962806701, 0.9759999963641167, 0.9758999963402748, 0.9760999962091446, 0.975799996316433, 0.9760999963283539, 0.9760999963283539, 0.9756999962925911, 0.9759999962449074, 0.9758999962806701, 0.975499996304512, 0.9756999962925911, 0.9760999963283539, 0.9760999962687492, 0.9761999962925911, 0.9759999963045121, 0.9759999963045121, 0.9757999962568283, 0.9758999962806701, 0.9758999962806701, 0.9759999962449074, 0.9759999963045121, 0.9756999963521957, 0.9760999962687492, 0.9757999962568283, 0.9762999963164329, 0.975799996316433, 0.9758999963402748, 0.9759999961853028, 0.9760999962687492, 0.9755999962091446, 0.975799996316433, 0.9759999963641167, 0.975799996316433, 0.9760999963879585, 0.9754999962449074, 0.9759999962449074, 0.9760999963283539, 0.9758999962806701, 0.9759999963045121, 0.9762999962568283, 0.9754999962449074, 0.9758999961614608, 0.9755999962687493, 0.9758999962806701, 0.9757999962568283, 0.9759999962449074, 0.9756999962329864, 0.9758999962806701, 0.9754999962449074, 0.9760999963283539, 0.9760999962687492, 0.9758999963402748, 0.9759999963045121, 0.9756999962329864, 0.9755999962687493, 0.9758999962806701, 0.9759999963045121, 0.9758999962210655, 0.9760999962091446, 0.9758999961614608, 0.9755999962687493, 0.9755999962091446, 0.9756999962329864, 0.9756999961733818, 0.9761999962925911, 0.9762999962568283, 0.9761999962925911, 0.9757999962568283, 0.9759999961853028, 0.9760999962687492, 0.9755999962687493, 0.9759999964237213, 0.9762999962568283, 0.9761999961733818, 0.9762999961972236, 0.9760999962687492, 0.9755999963283539, 0.9759999961853028, 0.9755999962687493, 0.9759999962449074, 0.9762999962568283, 0.9756999962925911, 0.9760999962091446, 0.9759999962449074, 0.9760999962687492, 0.9761999962925911, 0.9758999962806701, 0.9758999962210655, 0.9759999962449074, 0.9760999962091446, 0.9760999962687492, 0.9760999963283539, 0.9758999962806701, 0.9759999962449074, 0.9759999962449074, 0.9759999963045121, 0.9758999962210655, 0.9762999962568283, 0.9756999962329864, 0.9758999962806701, 0.9758999962806701, 0.9758999961614608, 0.9760999962687492, 0.9758999963998795, 0.9756999962925911, 0.9762999962568283, 0.9757999961972237, 0.9759999962449074, 0.9760999962091446, 0.9759999963045121, 0.9758999962806701, 0.9761999962329865, 0.9757999961972237, 0.9758999962210655, 0.9759999962449074, 0.9760999962091446, 0.9758999962806701, 0.9761999962329865, 0.9762999961972236, 0.9759999961853028, 0.9758999962806701, 0.9760999962687492, 0.9758999961614608, 0.9755999962687493, 0.9758999962210655, 0.9758999962806701, 0.9758999962210655, 0.9760999962091446, 0.9760999963283539, 0.9758999962210655, 0.9757999962568283, 0.9758999962806701, 0.9756999962925911, 0.9758999962806701, 0.9759999962449074, 0.9755999962091446, 0.9763999962806702, 0.9758999962806701, 0.9759999963045121, 0.9757999962568283, 0.9759999962449074, 0.9759999962449074, 0.9760999962687492, 0.9759999962449074, 0.9759999961853028, 0.9760999962091446, 0.9760999962091446, 0.9759999963045121, 0.9758999962806701, 0.9759999962449074, 0.9758999962210655, 0.9759999963045121, 0.9761999962329865, 0.9759999962449074, 0.9758999962210655, 0.9757999961972237, 0.9758999962210655, 0.9758999962210655, 0.9759999961853028, 0.9756999962329864, 0.9758999962806701, 0.9757999962568283, 0.9759999961853028, 0.9759999962449074, 0.9759999962449074, 0.9758999961614608, 0.9757999961972237, 0.9755999962091446, 0.9757999961972237, 0.9759999962449074, 0.9760999962687492, 0.9759999961853028, 0.9758999962806701, 0.9758999962806701, 0.9757999961972237, 0.9758999962806701, 0.9759999961853028, 0.9759999962449074, 0.9758999962210655, 0.9760999962091446, 0.9759999962449074, 0.9758999961614608, 0.9758999962806701, 0.9758999962806701, 0.9760999962091446, 0.9758999962210655, 0.9758999961614608, 0.9759999961853028, 0.9757999961972237, 0.9757999962568283, 0.9762999963164329, 0.9759999962449074, 0.9759999962449074, 0.9757999961972237, 0.9759999961853028, 0.9759999961853028, 0.9758999961614608, 0.9758999962806701, 0.9758999962210655, 0.975799996137619, 0.9759999961853028, 0.9757999961972237, 0.9760999962091446, 0.9758999962210655, 0.9758999962210655, 0.9759999962449074, 0.9761999961733818, 0.9758999962806701, 0.9760999962687492, 0.9758999961614608, 0.9757999962568283, 0.9758999962806701, 0.9760999962091446, 0.9759999961853028, 0.9761999962329865, 0.9757999961972237, 0.9760999961495399, 0.9758999962806701, 0.9759999962449074, 0.975799996137619, 0.9759999961853028, 0.9758999962210655, 0.9759999961853028, 0.9759999961853028, 0.9758999962806701, 0.9758999961614608, 0.975799996137619, 0.9757999961972237, 0.9758999962210655, 0.9758999961614608, 0.9759999961256981, 0.9757999961972237, 0.9756999961733818, 0.9758999962806701, 0.9758999962806701, 0.9758999962210655, 0.9759999962449074, 0.9759999962449074, 0.9759999961853028, 0.9758999962210655, 0.975799996137619, 0.9760999962687492, 0.9758999962210655, 0.9758999962210655, 0.9758999962210655, 0.9759999962449074, 0.9756999962329864, 0.9759999961853028, 0.9760999962687492, 0.9758999962806701, 0.9761999962329865, 0.9759999961853028, 0.9757999961972237, 0.9759999961853028, 0.9758999962210655, 0.9756999961733818, 0.9758999962806701, 0.9757999961972237, 0.9755999962091446, 0.9758999961614608, 0.9759999961853028, 0.9756999962329864, 0.9760999962091446, 0.9757999961972237, 0.9760999962091446, 0.9759999962449074, 0.9759999961256981, 0.9759999961853028, 0.9756999961733818, 0.9761999962329865, 0.9758999962806701, 0.9755999962091446, 0.9759999962449074, 0.9757999962568283, 0.9757999962568283, 0.9759999961853028, 0.9758999962210655, 0.9756999962329864, 0.9757999961972237, 0.9760999962687492, 0.9757999961972237, 0.9757999961972237, 0.9758999961614608, 0.9758999961614608, 0.9759999961256981, 0.9760999962687492, 0.9757999961972237, 0.9756999962329864, 0.9760999962091446, 0.9756999962329864, 0.9757999961972237, 0.9759999961853028, 0.9759999961256981, 0.9758999961018562, 0.9759999962449074, 0.9756999961733818, 0.9756999961733818, 0.9757999961972237, 0.9760999962091446, 0.975799996137619, 0.9756999962329864, 0.9761999962329865, 0.9759999961853028, 0.9758999961018562, 0.9760999962091446, 0.9758999962210655, 0.9760999962687492, 0.9759999962449074, 0.9757999961972237, 0.9761999962329865, 0.9761999962329865, 0.9758999961614608, 0.9759999962449074, 0.9759999961256981, 0.9759999961256981, 0.9759999961853028, 0.975799996137619, 0.9759999962449074, 0.9760999962687492, 0.9757999961972237, 0.9759999961853028, 0.9762999961972236, 0.9760999962687492, 0.975799996137619, 0.9758999962210655, 0.9760999961495399, 0.975799996137619, 0.9758999961614608, 0.9760999961495399, 0.9758999961614608, 0.9758999961614608, 0.9758999961614608, 0.9758999961614608, 0.9759999961853028, 0.9760999962091446, 0.9758999961018562, 0.9760999963283539, 0.9760999962687492, 0.975799996137619, 0.9758999962210655, 0.9757999961972237, 0.9759999961256981, 0.9758999962210655, 0.9761999961733818, 0.9762999962568283, 0.9760999962091446, 0.9757999961972237, 0.9759999962449074, 0.9761999961733818, 0.9760999962091446, 0.975799996137619, 0.9760999961495399, 0.9758999961614608, 0.9760999962091446, 0.9756999961733818, 0.9760999962091446, 0.9759999961853028, 0.9760999962091446, 0.9759999961256981, 0.9760999962091446, 0.9759999962449074, 0.9761999962329865, 0.9761999962329865, 0.9760999962091446, 0.9758999961018562, 0.9760999961495399, 0.9759999961853028, 0.9760999961495399, 0.9756999962329864, 0.9762999961972236, 0.9759999962449074, 0.9759999962449074, 0.9758999961018562, 0.9761999961733818, 0.9759999961853028, 0.9760999962091446, 0.9758999962806701, 0.9761999961733818, 0.975799996137619, 0.9760999961495399, 0.9760999962091446, 0.9759999961853028, 0.9760999962091446, 0.975799996137619, 0.9760999962091446, 0.9759999962449074, 0.9760999961495399, 0.9758999962806701, 0.9761999961733818, 0.9759999961853028, 0.9757999961972237, 0.9760999962091446, 0.9761999962329865, 0.9756999961137771, 0.9760999962091446, 0.9760999961495399, 0.9760999962687492, 0.9761999962329865, 0.9759999961256981, 0.9758999962210655, 0.9760999962091446, 0.9760999962091446, 0.9759999962449074, 0.9758999961614608, 0.9762999961972236, 0.9759999961853028, 0.9759999962449074, 0.9761999961733818, 0.9761999962329865, 0.9761999962329865, 0.9758999961614608, 0.9761999961733818, 0.9762999961972236, 0.9760999962091446, 0.9762999961972236, 0.9761999961733818, 0.9760999961495399, 0.9759999961853028, 0.9758999962210655, 0.9762999961972236, 0.9760999962091446, 0.9761999961733818, 0.975799996137619, 0.9760999962091446, 0.9760999961495399, 0.9759999962449074, 0.9760999962091446, 0.9759999961853028, 0.9761999961733818, 0.9759999963045121, 0.9762999961972236, 0.9760999963283539, 0.9760999962091446, 0.9761999962329865, 0.9760999962091446, 0.9759999961853028, 0.9761999961733818, 0.9760999962091446, 0.9758999961018562, 0.9760999962091446, 0.9759999962449074, 0.9760999962091446, 0.9762999961972236, 0.9761999961733818, 0.9761999961733818, 0.9759999961256981, 0.9759999961853028, 0.9761999961733818, 0.9758999961614608, 0.9759999961853028, 0.9758999961614608, 0.9760999962091446, 0.9760999962091446, 0.9759999961853028, 0.9761999961733818, 0.9761999962329865, 0.9760999962091446, 0.9761999961733818, 0.9759999961853028, 0.9760999962091446, 0.9759999961853028, 0.9760999962091446, 0.9759999961256981, 0.9760999962687492, 0.9759999962449074, 0.9760999961495399, 0.9761999962329865, 0.9761999962329865, 0.9760999962687492, 0.9761999962329865, 0.9761999962329865, 0.9761999961733818, 0.9760999962091446, 0.9761999961733818, 0.9758999961614608, 0.9761999962329865, 0.9760999962091446, 0.9760999961495399, 0.9761999961733818, 0.9759999961853028, 0.9761999961733818, 0.9762999961972236, 0.9762999961972236, 0.9761999961733818, 0.9760999962091446, 0.9759999961853028, 0.9759999961853028, 0.9760999962091446, 0.9761999961733818, 0.9760999962687492, 0.9760999961495399, 0.9761999961733818, 0.9761999961733818, 0.9761999961733818, 0.9761999961733818, 0.9761999961733818, 0.9760999962091446, 0.9762999961972236, 0.9761999961733818, 0.9762999961972236, 0.9759999961853028, 0.9760999962091446, 0.9760999962091446, 0.9759999961256981, 0.9761999961733818, 0.9759999961853028, 0.9759999961853028, 0.9759999961853028, 0.9759999961853028, 0.9760999962091446, 0.9759999961256981, 0.9760999961495399, 0.9760999961495399, 0.9760999962091446, 0.9761999961733818, 0.9759999961853028, 0.9760999962091446, 0.9761999962329865, 0.9759999961853028, 0.9762999961972236, 0.9759999961853028, 0.9759999961256981, 0.9758999961614608, 0.9761999961733818, 0.9759999962449074, 0.9758999961614608, 0.9760999962091446, 0.9760999961495399, 0.9759999961853028, 0.9761999961733818, 0.9760999962091446, 0.9760999961495399, 0.9761999961733818, 0.9759999961853028, 0.9760999961495399, 0.9761999962329865, 0.9760999961495399, 0.9759999961853028, 0.9760999961495399, 0.9759999961853028, 0.9761999962329865, 0.9761999962329865, 0.9761999961733818, 0.9760999962091446, 0.9760999961495399, 0.9761999961733818, 0.9761999961733818, 0.9760999961495399, 0.9758999961614608, 0.9759999961853028, 0.9761999962329865, 0.9760999962091446, 0.9761999962329865, 0.9761999961733818, 0.9762999961972236, 0.9761999961733818, 0.9760999961495399, 0.9761999962329865, 0.9759999961256981, 0.9760999962091446, 0.9761999962329865, 0.9760999961495399, 0.9759999961853028, 0.9760999961495399, 0.9760999962091446, 0.9760999962091446, 0.9759999961853028, 0.9761999962329865, 0.9760999961495399, 0.9759999961256981, 0.9760999961495399, 0.9760999961495399, 0.9760999961495399, 0.9760999961495399, 0.9760999961495399, 0.9761999962329865, 0.9762999962568283, 0.9761999961733818, 0.9760999961495399, 0.9760999961495399, 0.9760999961495399, 0.9759999961853028, 0.9759999961853028, 0.9761999962329865, 0.9760999961495399, 0.9761999961733818, 0.9761999961733818, 0.9760999961495399, 0.9760999962091446, 0.9759999961853028, 0.9762999961972236, 0.9761999961733818, 0.9761999961733818, 0.9762999961972236, 0.9760999961495399, 0.9761999962329865, 0.9759999961853028, 0.9761999961733818, 0.9761999961733818, 0.9760999962091446, 0.9760999962091446, 0.9759999961853028, 0.9760999961495399, 0.9761999961733818, 0.9762999961972236, 0.9760999962091446, 0.9761999961733818, 0.9760999962091446, 0.9761999962329865, 0.9760999962091446, 0.9760999961495399, 0.9760999962091446, 0.9760999962091446, 0.9760999962091446, 0.9760999961495399, 0.9761999961733818, 0.9761999962925911, 0.9760999961495399, 0.9759999961853028, 0.9759999961853028, 0.9759999961853028, 0.9759999961853028, 0.9762999961972236, 0.9759999961853028, 0.9760999962091446, 0.9759999961853028, 0.9760999962091446, 0.9761999961733818, 0.9760999961495399, 0.9762999961972236, 0.9761999961733818, 0.9759999961853028, 0.9760999962091446, 0.9760999962091446, 0.9760999962091446, 0.9760999961495399, 0.9761999961733818, 0.9761999961733818, 0.9760999962091446, 0.9762999961972236, 0.9759999961853028, 0.9761999961733818, 0.9759999961853028, 0.9760999962091446, 0.9760999962091446, 0.9762999961972236, 0.9760999961495399, 0.9761999961733818, 0.9761999962329865, 0.9761999962329865, 0.9760999961495399, 0.9759999961256981, 0.9762999961972236, 0.9761999961733818, 0.9761999961733818, 0.9760999961495399, 0.9759999961853028, 0.9760999962091446, 0.9762999961972236, 0.9761999961733818, 0.9760999961495399, 0.9761999962329865, 0.9761999962329865, 0.9760999962091446, 0.9760999962091446, 0.9760999962091446, 0.9759999961853028, 0.9761999961733818, 0.9762999961972236, 0.9763999961614609, 0.9761999961733818, 0.9761999962329865, 0.9761999961733818, 0.9763999961614609, 0.9761999961733818, 0.9759999961853028, 0.9759999961853028]\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10,\n",
    "                validation_data=(X_test, Y_test))\n",
    "print(hist.history['loss'])\n",
    "print(hist.history['acc'])\n",
    "print(hist.history['val_loss'])\n",
    "print(hist.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
